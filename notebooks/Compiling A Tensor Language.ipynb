{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('../src/')\n",
    "from adt import ADT\n",
    "from adt import memo as ADTmemo\n",
    "from atlv0 import IR as IRv0\n",
    "from atlv0 import Func\n",
    "import numpy as np\n",
    "import time\n",
    "from halide import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall our Tensor Language:\n",
    "\n",
    "$$\n",
    "\\newcommand{\\or}{\\ |\\ }\n",
    "\\begin{array}{rl}\n",
    "  e &= x \\or c \\or e_0 + e_1 \\or e_0 \\cdot e_1 \\\\\n",
    "  &\\or \\sum_i e \\or \\boxplus_i e \\or e_i \\or [i=j] \\\\\n",
    "  &\\or (e_0,e_1) \\or \\pi_0 e \\or \\pi_1 e \\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "When we last left off, we had designed an IR, with:\n",
    "* some operator overloading to make input slightly more convenient\n",
    "* string and LaTeX display routines\n",
    "* typechecking\n",
    "* a slow Python intepreter\n",
    "\n",
    "We took a detour into wrapping up the Halide language in a Python wrapper.  Now that we've done that, we can import Halide as a high-quality, JiT-ready code generator.  The main goal of this notebook is to work out how to compile the tensor language to that target in the simplest, most direct way possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note...\n",
    "In transfering the tensor language work to a `src/` directory Python script, `T0` was renamed to `IR`.  Some other changes were also made to clean up the results and function interface a bit into a more canonical usage pattern.  I will not review all of those changes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NumPy Arrays\n",
    "\n",
    "In Python, large amounts of numeric data are most commonly stored, managed and accessed via `NumPy`.  For this reason, we'll try to bind in these arrays as the representation of our tensor data.  Doing so will give us a high degree of interoperability with the Python ecosystem.\n",
    "\n",
    "To begin, let's just restate some of the constants we were working with before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4., 7., 1.]), array([[5. , 2. , 0. ],\n",
       "        [2.2, 0. , 4.5],\n",
       "        [0. , 6.1, 3.3]]), array([0., 0., 1.]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xv = np.array([4.,7.,1.], order='F')\n",
    "Av = np.array([[5.,2.,0.],[2.2,0.,4.5],[0.,6.1,3.3]], order='F')\n",
    "cv = np.array([0.,0.,1.], order='F')\n",
    "\n",
    "xv, Av, cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, observe the following metadata about the nd-array that we can retrieve via introspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flags:      C_CONTIGUOUS : False\n",
      "  F_CONTIGUOUS : True\n",
      "  OWNDATA : True\n",
      "  WRITEABLE : True\n",
      "  ALIGNED : True\n",
      "  WRITEBACKIFCOPY : False\n",
      "  UPDATEIFCOPY : False\n",
      "ndim:     2\n",
      "shape:    (3, 3)\n",
      "strides:  (8, 24)\n",
      "data:     <memory at 0x10e527990>\n",
      "size:     9\n",
      "itemsize: 8\n",
      "nbytes:   72\n"
     ]
    }
   ],
   "source": [
    "def nparr_data(a):\n",
    "    print(f'flags:    {a.flags}')\n",
    "    print(f'ndim:     {a.ndim}')\n",
    "    print(f'shape:    {a.shape}')\n",
    "    print(f'strides:  {a.strides}')\n",
    "    print(f'data:     {a.data}')\n",
    "    print(f'size:     {a.size}')\n",
    "    print(f'itemsize: {a.itemsize}')\n",
    "    print(f'nbytes:   {a.nbytes}')\n",
    "    \n",
    "#nparr_data(xv)\n",
    "nparr_data(Av)\n",
    "#nparr_data(cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ndim` gives us the order of the tensor, referred to as _the number of dimensions_.  `shape` then gives us those _dimensions_ themselves.  So this says we have a $3\\times 3$ matrix.  The `strides` are very important not for our conceptual picture, but for translating between the mathematical indexing and the actual address of data.  These correspond to the same strides used in Halide's buffers.  Great!  This should clearly make things easy.\n",
    "\n",
    "`size` should just be the product of the dimensions.  And `itemsize` tells us how many bytes each entry takes.  *note* importantly that the strides above are all given in bytes, whereas Halide's buffers expect strides divided by the byte-size.  That is, we would want to describe the strides here to Halide as `(24/8,8/8)`, i.e. `(3,1)`.  `nbytes` might be useful if we start doing manual memory management (e.g. allocating data on the GPU).\n",
    "\n",
    "Lastly, consider the flags here.  These are _not_ the same as `halide_buffer_t.flags`, which appear to be used just for keeping track of whether data is dirty.  Here, the `C_CONTIGUOUS` and `F_CONTIGUOUS` flags can be subordinated to a more thorough analysis of the strided description of layout.\n",
    "\n",
    "`OWNDATA` allows NumPy to wrap data arrays that it is borrowing from other sources.  For instance, we could choose to manage memory ourselves but expose NumPy handles onto our internally managed memory.  (There are some good reasons to do this, but it's more responsibility than we want right now.)\n",
    "\n",
    "`WRITABLE` and `WRITEBACKIFCOPY` control writing policies. (`UPDATEIFCOPY` is deprecated.)  The write-back establishes behavior to a write-back cache in a memory hierarchy.  Write-back is supposed to be triggered when this array object is destroyed, with the implication that this array does _not_ own its own data.  Writable is... well it's writable.  Importantly the flag allows for wrapping data as read only.\n",
    "\n",
    "Lastly `ALIGNED` tells us whether the data is allocated in a way that will play nicely with the memory/cache system.  (Does Halide ensure anything about this?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's up with `data`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "memoryview"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(Av.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's not a pointer...  Well, we can get a `uint8_t *` pointer pretty simply."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<halide.LP_c_ubyte at 0x10e531ea0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Av.ctypes.data_as(ctypes.POINTER(ctypes.c_ubyte))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the type of the array?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('float64'), numpy.dtype)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Av.dtype, type(Av.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.float64, type)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Av.dtype.type, type(Av.dtype.type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poking around reveals that the following are good Numpy types that should correspond to all the basic types we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.int8,\n",
       " numpy.int16,\n",
       " numpy.int32,\n",
       " numpy.int64,\n",
       " numpy.uint8,\n",
       " numpy.uint16,\n",
       " numpy.uint32,\n",
       " numpy.uint64,\n",
       " numpy.float32,\n",
       " numpy.float64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.int8, np.int16, np.int32, np.int64,\n",
    " np.uint8, np.uint16, np.uint32, np.uint64,\n",
    " np.float32, np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, numpy.float32, numpy.float64, numpy.int8, True, numpy.uint64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.float is float, np.float32, np.double, np.byte, np.int is int, np.uint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrap a NumPy Array for Halide\n",
    "\n",
    "Recall the `halide_buffer_t` structure, and some defaults we worked out for some of it.\n",
    "\n",
    "```\n",
    "struct halide_buffer_t {\n",
    "    uint64_t        device = 0,\n",
    "    void *          device_interface = null,\n",
    "    uint8_t *       host,\n",
    "    uint64_t        flags = 0,\n",
    "    halide_type_t   type,\n",
    "    uint32_t        dimensions,\n",
    "    halide_dimension_t * dim, // array of...\n",
    "    void *          padding = null,\n",
    "};\n",
    "```\n",
    "\n",
    "`host` will receive the pointer we just sketched out, `type` will need to be introspected on, and `dim` ought to be deducible from the strides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndarray_to_halide_buf(a):\n",
    "    def typ_convert(dt):\n",
    "        t = dt.type\n",
    "        # remapping to prevent some pointless errors\n",
    "        if t is float:\n",
    "            t = np.float64 if (sys.float_info.max_exp == 1024) else np.float32\n",
    "        if t is int:   t = np.int32\n",
    "        # main case switch\n",
    "        if   t is np.int8:    return halide_type_t(C.type_int,8,1)\n",
    "        elif t is np.int16:   return halide_type_t(C.type_int,16,1)\n",
    "        elif t is np.int32:   return halide_type_t(C.type_int,32,1)\n",
    "        elif t is np.int64:   return halide_type_t(C.type_int,64,1)\n",
    "        elif t is np.uint8:   return halide_type_t(C.type_uint,8,1)\n",
    "        elif t is np.uint16:  return halide_type_t(C.type_uint,16,1)\n",
    "        elif t is np.uint32:  return halide_type_t(C.type_uint,32,1)\n",
    "        elif t is np.uint64:  return halide_type_t(C.type_uint,64,1)\n",
    "        elif t is np.float32: return halide_type_t(C.type_float,32,1)\n",
    "        elif t is np.float64: return halide_type_t(C.type_float,64,1)\n",
    "        else:\n",
    "            raise TypeError(f\"unexpected type {t}\")\n",
    "    \n",
    "    buf  = halide_buffer_t()\n",
    "    buf.device              = 0\n",
    "    buf.device_interface    = None\n",
    "    buf.host                = a.ctypes.data_as(ctypes.POINTER(ctypes.c_ubyte))\n",
    "    buf.flags               = 0\n",
    "    buf.type                = typ_convert(a.dtype)\n",
    "    buf.dimensions          = a.ndim\n",
    "    buf.dim                 = (halide_dimension_t * a.ndim)()\n",
    "    # now loop through and sort out each dimension\n",
    "    for k in range(0,a.ndim):\n",
    "        s = int(a.strides[k] / a.itemsize)\n",
    "        assert a.strides[k] % a.itemsize == 0\n",
    "        buf.dim[k] = halide_dimension_t(0,a.shape[k],s,0)\n",
    "    buf.padding             = None\n",
    "    \n",
    "    return buf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<halide.halide_buffer_t at 0x10bac4d90>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ahv = ndarray_to_halide_buf(Av)\n",
    "Ahv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Revisiting the IR: \n",
    "\n",
    "Recall the definition of our IR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "module IR_v0 {\n",
      "    expr = Var      ( string name )\n",
      "         | Const    ( float  val  )\n",
      "         | Add      ( expr lhs, expr rhs )\n",
      "         | Mul      ( expr lhs, expr rhs )\n",
      "         | Pair     ( expr lhs, expr rhs )\n",
      "         | Proj     ( int01 idx, expr arg )\n",
      "         | Gen      ( string idxname, int range, expr body )\n",
      "         | Sum      ( string idxname, int range, expr body )\n",
      "         | Access   ( expr  base, index idx )\n",
      "         -- implied multiplication of the bracket with body\n",
      "         | Indicate ( pred  arg, expr body )\n",
      "         -- important to express sharing of computation results\n",
      "         | Let      ( string name, expr rhs, expr body )\n",
      "    \n",
      "    -- indices are drawn from a range s.t.\n",
      "    -- 0 <= i < range\n",
      "    \n",
      "    pred    = Eq( index lhs, index rhs )\n",
      "    \n",
      "    type    = TNum    ()\n",
      "            | TError  ()\n",
      "            | TPair   (  type lhs, type rhs )\n",
      "            | TTensor ( int range, type typ )\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(IRv0._defstr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminating Pairs... Detour into Typechecking\n",
    "\n",
    "Halide does not have a first-class construct for pair-values.  Therefore, we need to eliminate our dependence on pairs (as much as possible).  Doing this will require pushing $\\pi_k$ down, and pulling $(\\ ,\\ )$ up.  How does this work?  We must figure out how to exchange (\"commute\") these two operations with every other operation.\n",
    "\n",
    "The most distinctive rule is the one where the two forms cancel against each other\n",
    "\n",
    "$$ \\pi_k ( e_0, e_1 ) \\to e_k $$\n",
    "\n",
    "Beside that we have a set of useful rules.\n",
    "\n",
    "$$\n",
    "\\begin{array}{rcl}\n",
    "\\pi_k [i=j] e &\\to& [i=j] \\pi_k e \\\\\n",
    "\\pi_k \\boxplus_i e &\\to& \\boxplus_i \\pi_k e \\\\\n",
    "\\pi_k e[i] &\\to& (\\pi_k e)[i] \\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "Typing tells us we don't have to worry about projecting constants, additions, multiplications, or big-sums.  But by that reasoning, we oughtn't be able to exchange projection with indexing or array generation.  Those re-writes change the type!  Likewise, we don't know what to do about `Let` or `Var`.  These examples reveal a deficiency of the prior IR.  It lacks typing information.  What we need to do is develop a new _typed_ IR, and revisit type-checking to convert one IR to the other.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "When we change the IR below, we'll take the opportunity to replace name `string`s with `Sym`bol objects.  Doing this will allow us to create copies of names with the same original \"string name\" but distinct identities.  Generally, it's easier to get program re-writes correct once you adopt identifiers-as-symbols instead of identifiers-as-strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sym:\n",
    "    unq_count   = 1\n",
    "    \n",
    "    def __init__(self,nm):\n",
    "        self._nm    = nm\n",
    "        self._id    = Sym.unq_count\n",
    "        Sym.unq_count += 1\n",
    "    \n",
    "    def __str__(self):\n",
    "        return self._nm\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"{self._nm}${self._id}\"\n",
    "    \n",
    "    def name(self):\n",
    "        return self._nm\n",
    "    \n",
    "    def copy(self):\n",
    "        return Sym(self._nm)\n",
    "    \n",
    "\n",
    "IR = ADT(\"\"\"\n",
    "module IR {\n",
    "    expr = Var      ( symbol name )\n",
    "         | Const    ( float  val  )\n",
    "         | Add      ( expr lhs, expr rhs )\n",
    "         | Mul      ( expr lhs, expr rhs )\n",
    "         | Pair     ( expr lhs, expr rhs )\n",
    "         | Proj     ( int01 idx, expr arg )\n",
    "         | Gen      ( symbol idxname, int range, expr body )\n",
    "         | Sum      ( symbol idxname, int range, expr body )\n",
    "         | Access   ( expr  base, index idx )\n",
    "         -- implied multiplication of the bracket with body\n",
    "         | Indicate ( pred  arg, expr body )\n",
    "         -- important to express sharing of computation results\n",
    "         | Let      ( symbol name, expr rhs, expr body )\n",
    "         attributes( type typ )\n",
    "    \n",
    "    -- indices are drawn from a range s.t.\n",
    "    -- 0 <= i < range\n",
    "    \n",
    "    pred    = Eq( index lhs, index rhs )\n",
    "}\n",
    "\"\"\", {\n",
    "    'int01':  lambda x:  x == 0 or x == 1,\n",
    "    'index':  lambda x:  (type(x) is int) or (type(x) is Sym),\n",
    "    'symbol': lambda x: type(x) is Sym,\n",
    "    'type':   lambda x:  isinstance(x, IRv0.type)\n",
    "})\n",
    "# copy over types from the old module...\n",
    "for nm in ['tnum','terr','type','TNum','TError','TPair','TTensor']:\n",
    "    setattr(IR,nm,getattr(IRv0,nm))\n",
    "del nm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from atlv0 import TCError\n",
    "from atlv0 import _Context\n",
    "\n",
    "class TypeChecker:\n",
    "    def __init__(self, expr, initsymtyps):\n",
    "        self._ctxt   = _Context()\n",
    "        for nm,symtyp in initsymtyps.items():\n",
    "            assert type(symtyp[0]) is Sym\n",
    "            assert isinstance(symtyp[1], IR.type)\n",
    "            self._ctxt.set(nm,symtyp)\n",
    "        self._errors = []\n",
    "        self._out_ir = self.check(expr)\n",
    "        self.report_errors()\n",
    "\n",
    "    def get_out_ir(self):\n",
    "        return self._out_ir\n",
    "    \n",
    "    def _err(self, node, msg):\n",
    "        # might want to discern location\n",
    "        # via `node` eventually\n",
    "        self._errors.append(msg)\n",
    "    \n",
    "    def report_errors(self):\n",
    "        if len(self._errors) > 0:\n",
    "            raise TCError('Found errors during typechecking:\\n  '+\n",
    "                          '\\n  '.join(self._errors))\n",
    "    \n",
    "    def _get_ivar(self, node, name):\n",
    "        symtyp  = self._ctxt.get(name)\n",
    "        if symtyp == None:\n",
    "            self._err(node, f\"index variable '{name}' was undefined\")\n",
    "        elif type(symtyp[1]) is not int:\n",
    "            self._err(node, f\"variable '{name}' was \"\n",
    "                            f\"not bound as an index variable\")\n",
    "        else: return symtyp\n",
    "        # on failure fallthrough\n",
    "        return (Sym(name),None)\n",
    "    \n",
    "    def _get_var(self, node, name):\n",
    "        symtyp  = self._ctxt.get(name)\n",
    "        if symtyp == None: \n",
    "            self._err(node, f\"variable '{name}' was undefined\")\n",
    "        elif not isinstance(symtyp[1], IR.type):\n",
    "            self._err(node, f\"variable '{name}' was \"\n",
    "                            f\"not bound as a variable\")\n",
    "        else: return symtyp\n",
    "        # on failure fallthrough\n",
    "        return (Sym(name),IR.terr)\n",
    "    \n",
    "    def check(self, node):\n",
    "        nclass = type(node)\n",
    "        if   nclass is IRv0.Var:\n",
    "            sym,typ = self._get_var(node, node.name)\n",
    "            if typ == None: typ = IR.terr\n",
    "            return IR.Var(sym, typ)\n",
    "\n",
    "        elif nclass is IRv0.Const:\n",
    "            return IR.Const(node.val,IR.tnum)\n",
    "        \n",
    "        elif nclass is IRv0.Add or nclass is IRv0.Mul:\n",
    "            lhs = self.check(node.lhs)\n",
    "            rhs = self.check(node.rhs)\n",
    "            typ = IR.tnum if (lhs.typ == IR.tnum and\n",
    "                              rhs.typ == IR.tnum) else IR.terr\n",
    "            if lhs.typ != IR.tnum and lhs.typ != IR.terr:\n",
    "                self._err(node,\n",
    "                          f\"expected number on left-hand-side \"\n",
    "                          f\"of addition: {node}\")\n",
    "            if rhs.typ != IR.tnum and rhs.typ != IR.terr:\n",
    "                self._err(node,\n",
    "                          f\"expected number on right-hand-side \"\n",
    "                          f\"of addition: {node}\")\n",
    "            if nclass is IRv0.Add:\n",
    "                return IR.Add(lhs,rhs,typ)\n",
    "            else:\n",
    "                return IR.Mul(lhs,rhs,typ)\n",
    "        \n",
    "        elif nclass is IRv0.Pair:\n",
    "            lhs = self.check(node.lhs)\n",
    "            rhs = self.check(node.rhs)\n",
    "            typ = IR.terr\n",
    "            if lhs.typ != IR.terr and rhs.typ != IR.terr:\n",
    "                typ = IR.TPair(lhs.typ,rhs.typ)\n",
    "            return IR.Pair(lhs,rhs,typ)\n",
    "        \n",
    "        elif nclass is IRv0.Proj:\n",
    "            arg = self.check(node.arg)\n",
    "            typ = IR.terr\n",
    "            if   arg.typ == IR.terr: pass\n",
    "            elif type(arg.typ) is not IR.TPair:\n",
    "                self._err(node, f\"Was expecting a pair as argument: {node}\")\n",
    "            elif node.idx == 0: typ = arg.typ.lhs\n",
    "            else:               typ = arg.typ.rhs\n",
    "            return IR.Proj(node.idx,arg,typ)\n",
    "        \n",
    "        elif nclass is IRv0.Gen or nclass is IRv0.Sum:\n",
    "            self._ctxt.push()\n",
    "            newsym  = Sym(node.idxname)\n",
    "            self._ctxt.set(node.idxname, (newsym,node.range) )\n",
    "            body    = self.check(node.body)\n",
    "            self._ctxt.pop()\n",
    "            if   nclass is IRv0.Sum:\n",
    "                typ = body.typ\n",
    "                if typ != IR.tnum and typ != IR.terr:\n",
    "                    self._err(node, f\"Was expecting a number as body: {node}\")\n",
    "                    typ = IR.terr\n",
    "                return IR.Sum(newsym,node.range,body,typ)\n",
    "            else: # nclass is IRv0.Gen\n",
    "                typ = IR.terr\n",
    "                if body.typ != IR.terr:\n",
    "                    typ = IR.TTensor(node.range, body.typ)\n",
    "                return IR.Gen(newsym,node.range,body,typ)\n",
    "        \n",
    "        elif nclass is IRv0.Access:\n",
    "            base    = self.check(node.base)\n",
    "            sym,rng = self._get_ivar(node, node.idx)\n",
    "            typ     = IR.terr\n",
    "            if base.typ == IR.terr: pass\n",
    "            elif not isinstance(base.typ,IR.TTensor):\n",
    "                self._err(node, f\"Was expecting a tensor to index: {node}\")\n",
    "            elif rng == None:  pass\n",
    "            elif rng != base.typ.range:\n",
    "                self._err(node, f\"index variable '{node.idx}' was bound \"\n",
    "                                f\"to the range {rng}, but this tensor \"\n",
    "                                f\"expects an index of range {base.typ.range}\")\n",
    "            else:\n",
    "                typ = base.typ.typ\n",
    "            return IR.Access(base,sym,typ)\n",
    "        \n",
    "        elif nclass is IRv0.Indicate:\n",
    "            # need to check the predicate\n",
    "            eqnode      = node.arg\n",
    "            lsym, lrng  = self._get_ivar(node, eqnode.lhs)\n",
    "            rsym, rrng  = self._get_ivar(node, eqnode.rhs)\n",
    "            body        = self.check(node.body)\n",
    "            \n",
    "            if   lrng == None or rrng == None: pass\n",
    "            elif lrng != rrng:\n",
    "                self._err(node, f\"index variables \"\n",
    "                                f\"'{eqnode.lhs}' and '{eqnode.rhs}' \"\n",
    "                                f\"in equality are drawn from different\"\n",
    "                                f\"ranges: {lrng} and {rrng}\")\n",
    "            # can proceed with the body type regardless of errors\n",
    "            return IR.Indicate( IR.Eq(lsym,rsym), body, body.typ)\n",
    "        \n",
    "        elif nclass is IRv0.Let:\n",
    "            rhs     = self.check(node.rhs)\n",
    "            self._ctxt.push()\n",
    "            newsym  = Sym(node.name)\n",
    "            self._ctxt.set(node.name, (newsym,rhs.typ) )\n",
    "            body    = self.check(node.body)\n",
    "            self._ctxt.pop()\n",
    "            return IR.Let(newsym,rhs,body,body.typ)\n",
    "        \n",
    "        else:\n",
    "            assert false, \"Unexpected expression class for {node}\"\n",
    "\n",
    "# wrap type-checking in an object that we can use to keep track of\n",
    "# the arguments etc. with\n",
    "class TypedFunc:\n",
    "    def __init__(self,argtyps,expr):\n",
    "        self._orig_expr = expr\n",
    "        \n",
    "        # re-pack the args a few ways\n",
    "        self._arglist = []\n",
    "        self._argsyms = {}\n",
    "        self._symtyps = {}\n",
    "        assert type(argtyps) is list\n",
    "        for nm,typ in argtyps:\n",
    "            self._arglist.append( (nm,typ) )\n",
    "            s = Sym(nm)\n",
    "            self._argsyms[nm] = s\n",
    "            self._symtyps[nm] = (s,typ)\n",
    "        \n",
    "        # run type-checking to get the modified IR\n",
    "        self._expr    = TypeChecker(expr,self._symtyps).get_out_ir()\n",
    "\n",
    "    def __str__(self):\n",
    "        args = \", \".join([ f\"{st[0]}:{st[1]}\"\n",
    "                           for n,st in self._symtyps.items() ])\n",
    "        return (f\"Function({args}) : {self._expr.typ}\\n\"\n",
    "                f\"    {self._expr.__str__(0,'    ')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a quick string representation just so that we're not flying totally blind on what the results of the typechecking were."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IR_typ_str_rep(t):\n",
    "    tclass = type(t)\n",
    "    s      = \"ERROR\"\n",
    "    if tclass is IR.TNum:\n",
    "        s  = \"R\"\n",
    "    elif tclass is IR.TPair:\n",
    "        s  = f\"({IR_typ_str_rep(t.lhs)},{IR_typ_str_rep(t.rhs)})\"\n",
    "    elif tclass is IR.TTensor:\n",
    "        s  = f\"[{t.range}]{IR_typ_str_rep(t.typ)}\"\n",
    "    return s\n",
    "IR.type.__str__ = IR_typ_str_rep\n",
    "    \n",
    "def IR_str_rep(e,prec=0,indent=\"\"):\n",
    "    def sub(e,p):\n",
    "        return IR_str_rep(e,p,indent)\n",
    "    eclass = type(e)\n",
    "    s      = \"ERROR\"\n",
    "    if   eclass is IR.Var:\n",
    "        s = e.name\n",
    "    elif eclass is IR.Const:\n",
    "        s = str(e.val)\n",
    "    elif eclass is IR.Add:\n",
    "        s = f\"{sub(e.lhs,2)} + {sub(e.rhs,2)}\"\n",
    "        if prec > 2: s = f\"({s})\"\n",
    "    elif eclass is IR.Mul:\n",
    "        s = f\"{sub(e.lhs,3)} * {sub(e.rhs,3)}\"\n",
    "        if prec > 3: s = f\"({s})\"\n",
    "    elif eclass is IR.Pair:\n",
    "        s = f\"({sub(e.lhs,0)},{sub(e.rhs,0)})\"\n",
    "    elif eclass is IR.Proj:\n",
    "        s = f\"{sub(e.arg,4)}.{e.idx}\"\n",
    "        if prec > 4: s = f\"({s})\"\n",
    "    elif eclass is IR.Gen or eclass is IR.Sum:\n",
    "        op = \"+\" if eclass is IR.Sum else \"Gen\"\n",
    "        s = f\"{op}({e.idxname}:{e.range}) {sub(e.body,1)}\"\n",
    "        if prec > 1: s = f\"({s})\"\n",
    "    elif eclass is IR.Access:\n",
    "        s = f\"{sub(e.base,5)}[{e.idx}]\"\n",
    "        if prec > 5: s = f\"({s})\"\n",
    "    elif eclass is IR.Indicate:\n",
    "        assert isinstance(e.arg, IR.Eq), 'sanity: pred is Eq'\n",
    "        s = f\"[{e.arg.lhs}={e.arg.rhs}]*{sub(e.body,3)}\"\n",
    "        if prec > 3: s = f\"({s})\"\n",
    "    elif eclass is IR.Let:\n",
    "        # note that this is ill-behaved formatting\n",
    "        # for lets nested inside of expressions\n",
    "        rhs  = sub(e.rhs,0)\n",
    "        body = sub(e.body,0)\n",
    "        s = f\"let {e.name} : {e.rhs.typ} = {rhs} in\\n{indent}{body}\"\n",
    "        if prec > 0: s = f\"({s})\"\n",
    "    return s\n",
    "\n",
    "IR.expr.__str__ = IR_str_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function(A:[3][3]R, x:[3]R, c:[3]R) : [3]R\n",
      "    Gen(i:3) c[i] + (+(j:3) A[i][j] * x[j])\n",
      "Function(A:[3][3]R) : R\n",
      "    +(i:3) A[i][i]\n",
      "Function(x:[3]R) : [3][3]R\n",
      "    Gen(i:3) Gen(j:3) [i=j]*x[i]\n"
     ]
    }
   ],
   "source": [
    "n   = 3\n",
    "R   = IR.tnum\n",
    "Rn  = IR.TTensor(n,R)\n",
    "Rnn = IR.TTensor(n,Rn)\n",
    "x   = IRv0.Var('x')\n",
    "A   = IRv0.Var('A')\n",
    "c   = IRv0.Var('c')\n",
    "i   = 'i'\n",
    "j   = 'j'\n",
    "\n",
    "y       = IRv0.Gen(i,n, c[i] + IRv0.Sum(j,n, A[i,j] * x[j] ))\n",
    "tr      = IRv0.Sum(i,n, A[i,i])\n",
    "diag    = IRv0.Gen(i,n,IRv0.Gen(j,n, IRv0.Eq(i,j) * x[i] ))\n",
    "\n",
    "Ty      = TypedFunc([('A',Rnn),('x',Rn),('c',Rn)], y)\n",
    "Ttr     = TypedFunc([('A',Rnn)], tr)\n",
    "Tdiag   = TypedFunc([('x',Rn)], diag)\n",
    "\n",
    "print(Ty)\n",
    "print(Ttr)\n",
    "print(Tdiag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminating Pairs (now with Typing!)\n",
    "\n",
    "We had three big problems when we last left off.\n",
    "\n",
    "1. If we try to eliminate pairs from an expression whose input or output types involve pairs, we may change the type of the expression.\n",
    "2. We are going to change the type of the expression internally.  Is this safe?\n",
    "3. We need to work through `Let` bindings; can types help with that?\n",
    "\n",
    "Key to all of these problems is the ability to analyze a type that mixes tensor-ing and pair-ing.  Let $A \\times B$ be a pair type and $[n]A$ be a tensor type.  Then, in some sense $[n](A \\times B) \\cong [n]A \\times [n]B$; that is, they define the same data.  In fact, this change-in-type is what we would call the AoS-to-SoA (array-of-structs to struct-of-arrays) transform.  Pushing pair constructs outwards will tend to induce this transformation to our code.\n",
    "\n",
    "On the type level, we can ask two simple questions.  First, does this type contain pairs somewhere?  Second, if we were to fully perform this transform, what would the resulting type be?  Both are useful functions to have around\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def typ_has_pairs(t):\n",
    "    tclass = type(t)\n",
    "    if tclass is IR.TPair: return True\n",
    "    elif tclass is IR.TTensor:\n",
    "        return typ_has_pairs(t.typ)\n",
    "    else: # tnum or terr\n",
    "        return False\n",
    "\n",
    "def typ_SoA_transform(t,rngs=[]):\n",
    "    tclass = type(t)\n",
    "    if t is IR.tnum or t is IR.terr:\n",
    "        # possibly unroll the ranges stack here\n",
    "        if len(rngs) > 0:\n",
    "            for r in reversed(rngs):\n",
    "                t = IR.TTensor(r,t)\n",
    "        return t\n",
    "    elif tclass is IR.TTensor:\n",
    "        rngs = rngs.copy()\n",
    "        rngs.append(t.range)\n",
    "        return typ_SoA_transform(t.typ,rngs)\n",
    "    elif tclass is IR.TPair:\n",
    "        return IR.TPair( typ_SoA_transform(t.lhs,rngs),\n",
    "                         typ_SoA_transform(t.rhs,rngs) )\n",
    "    else: assert false, \"impossible case\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "[3]R\n",
      "False\n",
      "[3][3]R\n",
      "True\n",
      "[3](R,R)\n",
      "True\n",
      "([3]R,[3]R)\n"
     ]
    }
   ],
   "source": [
    "print(typ_has_pairs(Rn))\n",
    "print(typ_SoA_transform( Rn ))\n",
    "print(typ_has_pairs(Rnn))\n",
    "print(typ_SoA_transform( Rnn ))\n",
    "Complex = IR.TPair(R,R)\n",
    "print(typ_has_pairs(Complex))\n",
    "Cn      = IR.TTensor(n,Complex)\n",
    "print(Cn)\n",
    "print(typ_has_pairs(Cn))\n",
    "print(typ_SoA_transform(Cn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this type transformation to guide our destructuring of `Let`-bound variables.  Suppose we have a binding $\\textrm{let } x = e_1 \\textrm{ in } e_2$ where the type of $x$ contains pairs.  Then, we can destructure it in the following way.  ($\\{ var \\mapsto expr \\}$ denotes a substitution in the following term)\n",
    "\n",
    "$$\\begin{array}{l}\n",
    "\\textrm{let } x_0 = \\pi_0 e_1 \\textrm{ in } \\\\\n",
    "\\textrm{let } x_1 = \\pi_1 e_1 \\textrm{ in } \\\\\n",
    "(\\{x \\mapsto (x_0,x_1)\\}e_2)\n",
    "\\end{array}$$\n",
    "\n",
    "Using the SoA transform as a guide, we can fully expand the let-binding into pair-free bindings.  Of course, these bindings will then have to be processed by pushing down the new $\\pi$ projections themselves.  However, doing this will suffice to ensure that all variable names become free of pairs before processing the definition and body separately.\n",
    "\n",
    "Note that this is only possible because we can now query our IR for the type in the middle, at the let-bindings.\n",
    "\n",
    "Recalling the previous rules (below), this gives us a complete rewrite system.  So long as none of the inputs or output types of an expression have pairs in them, this system should totally eliminate pairs from the code without otherwise significantly damaging the code structure.\n",
    "\n",
    "$$\n",
    "\\begin{array}{rcl}\n",
    "\\pi_k ( e_0, e_1 ) &\\to& e_k \\\\\n",
    "\\pi_k [i=j] e &\\to& [i=j] \\pi_k e \\\\\n",
    "\\pi_k \\boxplus_i e &\\to& \\boxplus_i \\pi_k e \\\\\n",
    "\\pi_k e[i] &\\to& (\\pi_k e)[i] \\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "We can adopt a push-down focused strategy in this case, where all of the projections are pushed down until they hit and annihilate the pair constructors.  As such, the algorithm proceeds by keeping track of a stack of projections currently being pushed down.  It must also keep around a variable substitution environment to handle the let-binding rule.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairEliminator:\n",
    "    def __init__(self,expr,arg_symtyps,rettyp):\n",
    "        self._expr      = expr\n",
    "        self._ctxt      = _Context()\n",
    "        \n",
    "        if typ_has_pairs(rettyp):\n",
    "            raise TypeError(f\"Cannot eliminate pairs from a function \"\n",
    "                            f\"whose return type is a pair\")\n",
    "        \n",
    "        for sym,typ in arg_symtyps.values():\n",
    "            if typ_has_pairs(typ):\n",
    "                raise TypeError(f\"Cannot eliminate pairs from a function \"\n",
    "                                f\"with pair-typed arguments\")\n",
    "            self._ctxt.set(sym,IR.Var(sym,typ))\n",
    "        \n",
    "        # do elimination\n",
    "        self._out_expr  = self.pushdown(expr)\n",
    "    \n",
    "    def get_result(self):\n",
    "        return self._out_expr\n",
    "    \n",
    "    def _get_ivar_sub(self,nm):\n",
    "        i = self._ctxt.get(nm)\n",
    "        assert not i is None, f'should be caught earlier: {nm}'\n",
    "        return i\n",
    "    \n",
    "    def _get_var_sub(self,nm):\n",
    "        e = self._ctxt.get(nm)\n",
    "        assert not e is None, f'should be caught earlier: {nm}'\n",
    "        return e\n",
    "    \n",
    "    def pushdown(self, e, projstk = []):\n",
    "        eclass = type(e)\n",
    "        if   eclass is IR.Var:\n",
    "            subst_e = self._get_var_sub(e.name)\n",
    "            # prevent infinite recursion and needless duplications\n",
    "            if (type(subst_e) is IR.Var and\n",
    "                subst_e.name == e.name and\n",
    "                subst_e.typ  == e.typ):\n",
    "                    assert(len(projstk) == 0)\n",
    "                    return e\n",
    "            else: # need to continue pushdown\n",
    "                return self.pushdown(subst_e, projstk)\n",
    "        \n",
    "        elif eclass is IR.Const:\n",
    "            assert len(projstk) == 0\n",
    "            return e\n",
    "        \n",
    "        elif eclass is IR.Add or eclass is IR.Mul:\n",
    "            assert len(projstk) == 0\n",
    "            lhs = self.pushdown(e.lhs, projstk)\n",
    "            rhs = self.pushdown(e.rhs, projstk)\n",
    "            return eclass(lhs, rhs, e.typ)\n",
    "        \n",
    "        # deconstruct it!\n",
    "        elif eclass is IR.Pair:\n",
    "            assert len(projstk) > 0\n",
    "            proj_i = projstk.pop()\n",
    "            if proj_i == 0:\n",
    "                return self.pushdown(e.lhs, projstk)\n",
    "            else:\n",
    "                return self.pushdown(e.rhs, projstk)\n",
    "        \n",
    "        elif eclass is IR.Proj:\n",
    "            projstk.append(e.idx)\n",
    "            return self.pushdown(e.arg, projstk)\n",
    "        \n",
    "        elif eclass is IR.Gen or eclass is IR.Sum:\n",
    "            self._ctxt.push()\n",
    "            idxname = e.idxname.copy()\n",
    "            self._ctxt.set(e.idxname,idxname)\n",
    "            body    = self.pushdown(e.body, projstk)\n",
    "            if eclass is IR.Gen:\n",
    "                TensorType = IR.TTensor(e.range, body.typ)\n",
    "                return IR.Gen(idxname, e.range, body, TensorType)\n",
    "            else:\n",
    "                assert body.typ == IR.tnum\n",
    "                return IR.Sum(idxname, e.range, body, body.typ)\n",
    "            \n",
    "        elif eclass is IR.Access:\n",
    "            base    = self.pushdown(e.base, projstk)\n",
    "            idx     = self._get_ivar_sub(e.idx)\n",
    "            assert type(base.typ) is IR.TTensor\n",
    "            return IR.Access(base, idx, base.typ.typ)\n",
    "            \n",
    "        elif eclass is IR.Indicate:\n",
    "            lidx    = self._get_ivar_sub(e.arg.lhs)\n",
    "            ridx    = self._get_ivar_sub(e.arg.rhs)\n",
    "            body    = self.pushdown(e.body, projstk)\n",
    "            return IR.Indicate(IR.Eq(lidx,ridx), body, body.typ)\n",
    "            \n",
    "        elif eclass is IR.Let:\n",
    "            soa_typ = typ_SoA_transform(e.rhs.typ)\n",
    "\n",
    "            # unpack the soa_typ into projections\n",
    "            binds   = []\n",
    "            def soa_unpack(nm,T,projstk=[]):\n",
    "                if type(T) is IR.TPair:\n",
    "                    projstk.insert(0,0)\n",
    "                    lhs     = soa_unpack(nm+'0',T.lhs,projstk)\n",
    "                    projstk.pop()\n",
    "                    projstk.insert(0,1)\n",
    "                    rhs     = soa_unpack(nm+'1',T.rhs,projstk)\n",
    "                    projstk.pop()\n",
    "                    assert lhs.typ == T.lhs\n",
    "                    assert rhs.typ == T.rhs\n",
    "                    return IR.Pair(lhs,rhs,T)\n",
    "                else:\n",
    "                    rval    = self.pushdown(e.rhs,projstk.copy())\n",
    "                    sym     = Sym(nm)\n",
    "                    assert rval.typ == T\n",
    "                    binds.append((sym,rval))\n",
    "                    return IR.Var(sym,T)\n",
    "            nm = e.name.name() + ('_' if (type(soa_typ) is IR.TPair) else '')\n",
    "            subst = soa_unpack(nm, soa_typ)\n",
    "            \n",
    "            # bind the soa-transformed variables, and rewrite body\n",
    "            self._ctxt.push()\n",
    "            self._ctxt.set(e.name,subst)\n",
    "            # ensure termination at the new let-bound variables\n",
    "            for sym,rhs in binds:\n",
    "                self._ctxt.set(sym,IR.Var(sym,rhs.typ))\n",
    "            body    = self.pushdown(e.body,projstk)\n",
    "            self._ctxt.pop()\n",
    "            \n",
    "            # construct the resulting let-binding chain\n",
    "            for sym,rhs in reversed(binds):\n",
    "                body = IR.Let(sym,rhs,body,body.typ)\n",
    "            return body\n",
    "\n",
    "def _TypedFunc_eliminate_pairs(self):\n",
    "    e       = self._expr\n",
    "    atyps   = self._symtyps\n",
    "    self._expr = PairEliminator(e,atyps,e.typ).get_result()\n",
    "TypedFunc.eliminate_pairs = _TypedFunc_eliminate_pairs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need some example to test.  How about this one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function(a:[3]R, b:[3]R) : R\n",
      "    let c3 : [3]((R,R),R) = Gen(j:3) ((a[j],b[j]),a[j] * b[j]) in\n",
      "    +(j:3) c3[j].0.0 + c3[j].0.1 + c3[j].1\n",
      "Function(a:[3]R, b:[3]R) : R\n",
      "    let c3_00 : [3]R = Gen(j:3) a[j] in\n",
      "    let c3_01 : [3]R = Gen(j:3) b[j] in\n",
      "    let c3_1 : [3]R = Gen(j:3) a[j] * b[j] in\n",
      "    +(j:3) c3_00[j] + c3_01[j] + c3_1[j]\n"
     ]
    }
   ],
   "source": [
    "a   = IRv0.Var('a')\n",
    "b   = IRv0.Var('b')\n",
    "i,j = 'i','j'\n",
    "ab3 = IRv0.Let('c3',IRv0.Gen(j,n, IRv0.Pair( IRv0.Pair(a[j], b[j]),\n",
    "                                             a[j]*b[j] )),\n",
    "               IRv0.Sum(j,n, IRv0.Proj(0, IRv0.Proj(0, IRv0.Var('c3')[j])) +\n",
    "                             IRv0.Proj(1, IRv0.Proj(0, IRv0.Var('c3')[j])) +\n",
    "                             IRv0.Proj(1, IRv0.Var('c3')[j]) ))\n",
    "\n",
    "Fab3 = TypedFunc( [('a',Rn),('b',Rn)], ab3 )\n",
    "print(Fab3)\n",
    "Fab3.eliminate_pairs()\n",
    "print(Fab3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let-Flattening\n",
    "\n",
    "We have now eliminated two forms from the IRâ€”two that we weren't sure how to compile into Halide.  However, doing this hardly takes us down to the point where we can simply emit Halide code.  In Halide, all statements occur at the top-level (i.e. not within other statements).  However, our language allows for nested `Let` bindings.  For instance, consider the following program.\n",
    "\n",
    "```\n",
    "Gen(i:n) Sum(j:n) let m = Sum(k:n) D[i,j,k]*a[k] in  m * b[j]\n",
    "```\n",
    "\n",
    "How can we move the `let m = ...` definition to the outermost-level?  If we did that naively, we would violate the scoping of the `i` and `j` variables.  Our only option is to close the right-hand-side of the binding in those variables.  That is,\n",
    "\n",
    "```\n",
    "let m = Gen(i:n) Gen(j:n) Sum(k:n) D[i,j,k]*a[k] in\n",
    "Gen(i:n) Sum(j:n) m[i,j] * b[j]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function(D:[3][3][3]R, a:[3]R, b:[3]R) : [3]R\n",
      "    Gen(i:3) +(j:3) (let m : R = +(k:3) D[i][j][k] * a[k] in\n",
      "    m * b[j])\n"
     ]
    }
   ],
   "source": [
    "k = 'k'\n",
    "D = IRv0.Var('D')\n",
    "Rnnn = IR.TTensor(n,Rnn)\n",
    "\n",
    "contract    = IRv0.Gen(i,n, IRv0.Sum(j,n,\n",
    "                IRv0.Let('m', IRv0.Sum(k,n, D[i,j,k] * a[k]),\n",
    "                         IRv0.Var('m') * b[j] )))\n",
    "\n",
    "Fcontract   = TypedFunc([('D',Rnnn),('a',Rn),('b',Rn)],contract)\n",
    "print(Fcontract)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can think of `Let`-flattening as a process that \"pulls up\" the `Let` bindings past all the other constructs in the language.  On a coding level, our goal will be to transform the program into a \"block\" consisting of a sequence of name/expression pairs, (i.e. statements) terminated by a \"return\" expression.  Sketching this rule means looking at how `Let` commutes with every other expression when \"pulled up\"...\n",
    "\n",
    "$$\\begin{array}{rcl}\n",
    "e_0 + (\\textrm{let } x = e_1 \\textrm{ in } e_2)\n",
    "&\\to& \\textrm{let } x = e_1 \\textrm{ in } (e_0 + e_2) \\\\\n",
    "e_0 \\cdot (\\textrm{let } x = e_1 \\textrm{ in } e_2)\n",
    "&\\to& \\textrm{let } x = e_1 \\textrm{ in } (e_0 \\cdot e_2) \\\\\n",
    "[i=j] \\cdot (\\textrm{let } x = e_1 \\textrm{ in } e_2)\n",
    "&\\to& \\textrm{let } x = e_1 \\textrm{ in } ([i=j] \\cdot e_2) \\\\\n",
    "\\boxplus_i\\ (\\textrm{let } x = e_1 \\textrm{ in } e_2)\n",
    "&\\to& \\textrm{let } x = (\\boxplus_i\\ e_1) \\textrm{ in }\n",
    "      (\\boxplus_i\\ \\{x \\mapsto x[i] \\}e_2) \\\\\n",
    "\\sum_i\\ (\\textrm{let } x = e_1 \\textrm{ in } e_2)\n",
    "&\\to& \\textrm{let } x = (\\boxplus_i\\ e_1) \\textrm{ in }\n",
    "      (\\sum_i\\ \\{x \\mapsto x[i] \\}e_2) \\\\\n",
    "(\\textrm{let } x = e_1 \\textrm{ in } e_2)[i]\n",
    "&\\to& \\textrm{let } x = e_1 \\textrm{ in } (e_2[i]) \\\\\n",
    "\\textrm{let } x = (\\textrm{ let } y = e_0 \\textrm{ in } e_1) \\textrm{ in } e_2\n",
    "&\\to& \\textrm{let } y = e_0 \\textrm{ in } (\\textrm{ let } x = e_1 \\textrm{ in } e_2) \\\\\n",
    "\\end{array}$$\n",
    "\n",
    "(_note of course that the + and * rules apply symmetrically with let on the left-hand-side of the operator_)\n",
    "\n",
    "If `Let` occurs in the body of another `Let`, that's fine.  That's exactly what we're aiming for when we talk about a \"block\".  In fact, these rules can all be generalized to \"blocks\" by understanding that to be the form of the `Let`-expressions being pulled up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LetFlatten:\n",
    "    def __init__(self,expr,arg_symtyps,rettyp):\n",
    "        self._expr      = expr\n",
    "        #self._ctxt      = _Context()\n",
    "        \n",
    "        # lift\n",
    "        binds, ret_e    = self.letlift(expr)\n",
    "        \n",
    "        # construct the final let-chained expression\n",
    "        e   = ret_e\n",
    "        for nm,rhs in reversed(binds):\n",
    "            e = IR.Let(nm,rhs,e,e.typ)\n",
    "        self._out_expr  = e\n",
    "    \n",
    "    def get_result(self):\n",
    "        return self._out_expr\n",
    "    \n",
    "    def letlift(self, e):\n",
    "        eclass = type(e)\n",
    "        assert not eclass is IR.Pair, \"pairs should be eliminated\"\n",
    "        assert not eclass is IR.Proj, \"pairs should be eliminated\"\n",
    "        if   eclass is IR.Var:\n",
    "            return [],e\n",
    "        elif eclass is IR.Const:\n",
    "            return [],e\n",
    "        \n",
    "        elif eclass is IR.Add or eclass is IR.Mul:\n",
    "            lbind, lhs  = self.letlift(e.lhs)\n",
    "            rbind, rhs  = self.letlift(e.rhs)\n",
    "            \n",
    "            return lbind + rbind, eclass(lhs, rhs, e.typ)\n",
    "        \n",
    "        elif eclass is IR.Gen or eclass is IR.Sum:\n",
    "            binds, body = self.letlift(e.body)\n",
    "            ctxt        = _Context()\n",
    "            i           = e.idxname\n",
    "            rng         = e.range\n",
    "            \n",
    "            new_binds   = []\n",
    "            for nm,rhs in binds:\n",
    "                rhs     = self.subst(ctxt,rhs)\n",
    "                T       = rhs.typ\n",
    "                TensorT = IR.TTensor(rng,T)\n",
    "                new_rhs = IR.Gen(i,rng,rhs,TensorT)\n",
    "                ctxt.set( nm, IR.Access(IR.Var(nm,TensorT), i, T) )\n",
    "                new_binds.append( (nm, new_rhs) )\n",
    "            new_body    = eclass(i,rng, self.subst(ctxt,body), e.typ)\n",
    "            \n",
    "            return new_binds, new_body\n",
    "            \n",
    "        elif eclass is IR.Access:\n",
    "            binds, base = self.letlift(e.base)\n",
    "            return binds, IR.Access(base, e.idx, e.typ)\n",
    "            \n",
    "        elif eclass is IR.Indicate:\n",
    "            binds, body = self.letlift(e.body)\n",
    "            return binds, IR.Indicate(e.arg, body, e.typ)\n",
    "            \n",
    "        elif eclass is IR.Let:\n",
    "            binds0, rhs     = self.letlift(e.rhs)\n",
    "            binds1, body    = self.letlift(e.body)\n",
    "            binds           = binds0 + [(e.name,rhs)] + binds1\n",
    "            return binds, body\n",
    "    \n",
    "    def subst(self, env, e):\n",
    "        eclass = type(e)\n",
    "        assert not eclass is IR.Pair, \"pairs should be eliminated\"\n",
    "        assert not eclass is IR.Proj, \"pairs should be eliminated\"\n",
    "        assert not eclass is IR.Let\n",
    "        if   eclass is IR.Var:\n",
    "            sub = env.get(e.name)\n",
    "            return e if sub is None else sub\n",
    "        \n",
    "        elif eclass is IR.Const:\n",
    "            return e\n",
    "        \n",
    "        elif eclass is IR.Add or eclass is IR.Mul:\n",
    "            lhs = self.subst(env, e.lhs)\n",
    "            rhs = self.subst(env, e.rhs)\n",
    "            return eclass(lhs,rhs,e.typ)\n",
    "        \n",
    "        elif eclass is IR.Gen or eclass is IR.Sum:\n",
    "            body    = self.subst(env, e.body)\n",
    "            return eclass(e.idxname, e.range, body, e.typ)\n",
    "            \n",
    "        elif eclass is IR.Access:\n",
    "            base    = self.subst(env, e.base)\n",
    "            return IR.Access(base, e.idx, e.typ)\n",
    "            \n",
    "        elif eclass is IR.Indicate:\n",
    "            body    = self.subst(env, e.body)\n",
    "            return IR.Indicate(e.arg, body, e.typ)\n",
    "\n",
    "def _TypedFunc_lift_lets(self):\n",
    "    e       = self._expr\n",
    "    atyps   = self._symtyps\n",
    "    self._expr = LetFlatten(e,atyps,e.typ).get_result()\n",
    "TypedFunc.lift_lets = _TypedFunc_lift_lets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function(D:[3][3][3]R, a:[3]R, b:[3]R) : [3]R\n",
      "    Gen(i:3) +(j:3) (let m : R = +(k:3) D[i][j][k] * a[k] in\n",
      "    m * b[j])\n",
      "Function(D:[3][3][3]R, a:[3]R, b:[3]R) : [3]R\n",
      "    let m : [3][3]R = Gen(i:3) Gen(j:3) +(k:3) D[i][j][k] * a[k] in\n",
      "    Gen(i:3) +(j:3) m[i][j] * b[j]\n",
      "Function(D:[3][3][3]R, a:[3]R, b:[3]R) : [3]R\n",
      "    let m : [3][3]R = Gen(i:3) Gen(j:3) +(k:3) D[i][j][k] * a[k] in\n",
      "    Gen(i:3) +(j:3) m[i][j] * b[j]\n",
      "Function(D:[3][3][3]R, a:[3]R, b:[3]R) : [3]R\n",
      "    let m : [3][3]R = Gen(i:3) Gen(j:3) +(k:3) D[i][j][k] * a[k] in\n",
      "    Gen(i:3) +(j:3) m[i][j] * b[j]\n"
     ]
    }
   ],
   "source": [
    "Fcontract   = TypedFunc([('D',Rnnn),('a',Rn),('b',Rn)],contract)\n",
    "print(Fcontract)\n",
    "Fcontract.lift_lets()\n",
    "print(Fcontract)\n",
    "# check for fixed-point behaviors\n",
    "Fcontract.eliminate_pairs()\n",
    "print(Fcontract)\n",
    "Fcontract.lift_lets()\n",
    "print(Fcontract)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gen-Normalization\n",
    "\n",
    "Flattening out all of the `Let` bindings into a statement block is a significant step towards compilation.  Is it the case that we can now translate all of these statements into Halide statements and be done with everything?  No.\n",
    "\n",
    "We would like to compile tensor bindings of the form\n",
    "```\n",
    "let f = Gen(i,j,...) e in\n",
    "...\n",
    "```\n",
    "where `e` is an expression absent any `Gen`s.\n",
    "\n",
    "To accomplish this, we must push down any `Access` occurences to eliminate spurious `Gen`s in the middle of the expressions.  Then, we must also push down any `Indicate` wrappers so that they only occur inside of the generators.\n",
    "\n",
    "Here are two examples to play with.  Note how the latter example includes an indicator function that might allow further simplifications but need not be used in that way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function(A:[3][3]R, x:[3]R) : R\n",
      "    +(k:3) (Gen(i:3) +(j:3) A[i][j] * x[j])[k] * x[k]\n",
      "Function(x:[3]R, a:[3]R) : R\n",
      "    +(j:3) +(i:3) a[j] * (Gen(i:3) Gen(j:3) [i=j]*x[i])[j][i] * a[i]\n"
     ]
    }
   ],
   "source": [
    "prod    = IRv0.Gen(i,n, IRv0.Sum(j,n, A[i,j] * x[j] ))\n",
    "qprod   = IRv0.Sum(k,n, prod[k]*x[k] )\n",
    "\n",
    "Fqprod  = TypedFunc([('A',Rnn),('x',Rn)],qprod)\n",
    "print(Fqprod)\n",
    "\n",
    "diag    = IRv0.Gen(i,n, IRv0.Gen(j,n, IRv0.Eq(i,j) * x[i] ))\n",
    "dprod   = IRv0.Sum(j,n, IRv0.Sum(i,n, a[j] * diag[j,i] * a[i] ))\n",
    "\n",
    "Fdprod  = TypedFunc([('x',Rn),('a',Rn)],dprod)\n",
    "print(Fdprod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing the minimum necessary simplifications will require invoking at least the following rewrite rules to lift all generators outwards.\n",
    "\n",
    "$$\\begin{array}{rcl}\n",
    "(\\boxplus_i\\ e)[j]\n",
    "  &\\to& \\{i \\mapsto j\\} e \\\\\n",
    "[j=k] \\cdot (\\boxplus_i\\ e)\n",
    "  &\\to& \\boxplus_i\\ [j=k] \\cdot e \\\\\n",
    "\\end{array}$$\n",
    "\n",
    "Another set of rewrites that can be handled concurrently tries to lift indicators out as far as possible without escaping `Let` bindings.  This can drastically reduce computational overhead in some cases.\n",
    "  \n",
    "$$\\begin{array}{rcl}\n",
    "([i=j]\\cdot e)[k] &\\to& [i=j]\\cdot(e[k]) \\\\\n",
    "([i=j]\\cdot e_1) \\cdot e_2 &\\to& [i=j]\\cdot(e_1 \\cdot e_2) \\\\\n",
    "\\sum_i ([j=k]\\cdot e) &\\to& [j=k]\\cdot(\\sum_i e) \\\\\n",
    "\\sum_i ([i=j]\\cdot e) &\\to& \\{i \\mapsto j\\}e \\\\\n",
    "\\end{array}$$\n",
    "\n",
    "Both of these sets of rewrites work by lifting out the focused form (`Gen` or `Indicate`).  However, the rule of the first set ensures that all `Gen` will end up outside all `Indicate` forms.  Therefore, a combination of these two strategies would seek to percolate outwards these forms together.  Some indicators may get trapped under simple sums; others will interact with big sums."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenNormalize:\n",
    "    def __init__(self,expr,arg_symtyps,rettyp):\n",
    "        self._expr = expr\n",
    "        \n",
    "        # break out into a list of bindings and return expr\n",
    "        binds, ret = self.to_block(expr)\n",
    "        \n",
    "        # normalize each expr\n",
    "        rebinds    = []\n",
    "        for sym,rhs in binds:\n",
    "            r      = self.final_lift_gen(rhs)\n",
    "            rebinds.append((sym,r))\n",
    "        ret        = self.final_lift_gen(ret)\n",
    "        \n",
    "        self._out_expr  = self.from_block(rebinds,ret)\n",
    "    \n",
    "    def get_result(self):\n",
    "        return self._out_expr\n",
    "    \n",
    "    def to_block(self, e):\n",
    "        binds = []\n",
    "        while type(e) is IR.Let:\n",
    "            binds.append((e.name,e.rhs))\n",
    "            e = e.body\n",
    "        return binds, e\n",
    "    \n",
    "    def from_block(self, binds, ret):\n",
    "        e = ret\n",
    "        for sym,rhs in reversed(binds):\n",
    "            e = IR.Let(sym,rhs,e,e.typ)\n",
    "        return e\n",
    "    \n",
    "    def wrap_ind(self, inds, e):\n",
    "        for p in inds:\n",
    "            e = IR.Indicate(p, e, e.typ)\n",
    "        return e\n",
    "    \n",
    "    def final_lift_gen(self, e):\n",
    "        gen, ind, e = self.lift_gen(e)\n",
    "        e           = self.wrap_ind(ind,e)\n",
    "        for idx,rng in gen:\n",
    "            T       = IR.TTensor(rng,e.typ)\n",
    "            e       = IR.Gen(idx,rng,e,T)\n",
    "        return e\n",
    "    \n",
    "    def lift_gen(self, e):\n",
    "        eclass = type(e)\n",
    "        assert not eclass is IR.Pair, \"pairs should be eliminated\"\n",
    "        assert not eclass is IR.Proj, \"pairs should be eliminated\"\n",
    "        assert not eclass is IR.Let\n",
    "        if   eclass is IR.Var or eclass is IR.Const:\n",
    "            return [], [], e\n",
    "        \n",
    "        elif eclass is IR.Add or eclass is IR.Mul:\n",
    "            lgen, lind, lhs = self.lift_gen(e.lhs)\n",
    "            rgen, rind, rhs = self.lift_gen(e.rhs)\n",
    "            assert len(lgen) == 0\n",
    "            assert len(rgen) == 0\n",
    "            if eclass is IR.Add:\n",
    "                lhs = self.wrap_ind(lind,lhs)\n",
    "                rhs = self.wrap_ind(rind,rhs)\n",
    "                return [], [], IR.Add(lhs,rhs,e.typ)\n",
    "            else:\n",
    "                return [], lind + rind, IR.Mul(lhs,rhs,e.typ)\n",
    "        \n",
    "        elif eclass is IR.Gen:\n",
    "            gen, ind, body  = self.lift_gen(e.body)\n",
    "            gen.append((e.idxname, e.range))\n",
    "            return gen, ind, body\n",
    "        \n",
    "        elif eclass is IR.Sum:\n",
    "            gen, ind, body  = self.lift_gen(e.body)\n",
    "            assert len(gen) == 0\n",
    "            # go through indicators and maybe find sum collapse\n",
    "            i = e.idxname\n",
    "            j = None\n",
    "            for p in ind:\n",
    "                if   p.lhs == i: j = p.rhs; break\n",
    "                elif p.rhs == i: j = p.lhs; break\n",
    "            if j is None:\n",
    "                body = IR.Sum(i,e.range,body,body.typ)\n",
    "            else:\n",
    "                ind, body   = self.subst(i,j,ind,body)\n",
    "            return [], ind, body\n",
    "            \n",
    "        elif eclass is IR.Access:\n",
    "            gen, ind, base  = self.lift_gen(e.base)\n",
    "            if len(gen) > 0:\n",
    "                i,r         = gen.pop()\n",
    "                ind, base   = self.subst(i,e.idx,ind,base)\n",
    "                return gen, ind, base\n",
    "            else:\n",
    "                return gen, ind, IR.Access(base, e.idx, e.typ)\n",
    "            \n",
    "        elif eclass is IR.Indicate:\n",
    "            gen, ind, body  = self.lift_gen(e.body)\n",
    "            # sanity!\n",
    "            for i,r in gen:\n",
    "                assert i != e.arg.lhs and i != e.arg.rhs\n",
    "            ind.append(e.arg)\n",
    "            return gen, ind, body\n",
    "            \n",
    "    def sub_ind(self, old, new, p):\n",
    "        assert type(p) is IR.Eq\n",
    "        lhs = new if p.lhs == old else p.lhs\n",
    "        rhs = new if p.rhs == old else p.rhs\n",
    "        return None if lhs == rhs else IR.Eq(lhs,rhs)\n",
    "    \n",
    "    def subst(self, old, new, ind, e):\n",
    "        # if there are indicators, process separately\n",
    "        if len(ind) > 0:\n",
    "            new_ind = []\n",
    "            for p in ind:\n",
    "                p = self.sub_ind(old,new,p)\n",
    "                if not p is None: new_ind.append(p)\n",
    "            # substitute the expression without indicators\n",
    "            _, e = self.subst(old,new,[],e)\n",
    "            return new_ind, e\n",
    "        \n",
    "        # the usual case for things other than indicator lists\n",
    "        eclass = type(e)\n",
    "        assert not eclass is IR.Pair, \"pairs should be eliminated\"\n",
    "        assert not eclass is IR.Proj, \"pairs should be eliminated\"\n",
    "        assert not eclass is IR.Let\n",
    "        assert not eclass is IR.Gen\n",
    "        if   eclass is IR.Var or eclass is IR.Const:\n",
    "            return [], e\n",
    "        \n",
    "        elif eclass is IR.Add or eclass is IR.Mul:\n",
    "            _, lhs  = self.subst(old,new,ind,e.lhs)\n",
    "            _, rhs  = self.subst(old,new,ind,e.rhs)\n",
    "            return [], eclass(lhs,rhs,e.typ)\n",
    "        \n",
    "        elif eclass is IR.Sum:\n",
    "            # probably shouldn't happen?\n",
    "            if e.idxname == old:\n",
    "                return e\n",
    "            _, body = self.subst(old,new,[],e.body)\n",
    "            return [], eclass(e.idxname, e.range, body, e.typ)\n",
    "            \n",
    "        elif eclass is IR.Access:\n",
    "            idx     = new if e.idx == old else e.idx\n",
    "            _, base = self.subst(old,new,[],e.base)\n",
    "            return [], IR.Access(base, idx, e.typ)\n",
    "            \n",
    "        elif eclass is IR.Indicate:\n",
    "            arg     = self.sub_ind(old,new,e.arg)\n",
    "            _, body = self.subst(old,new,[],e.body)\n",
    "            if arg is None: return [], body\n",
    "            else:           return [], IR.Indicate(arg,body,body.typ)\n",
    "\n",
    "def _TypedFunc_gen_normalize(self):\n",
    "    e       = self._expr\n",
    "    atyps   = self._symtyps\n",
    "    self._expr = GenNormalize(e,atyps,e.typ).get_result()\n",
    "TypedFunc.gen_normalize = _TypedFunc_gen_normalize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function(A:[3][3]R, x:[3]R) : R\n",
      "    +(k:3) (Gen(i:3) +(j:3) A[i][j] * x[j])[k] * x[k]\n",
      "Function(A:[3][3]R, x:[3]R) : R\n",
      "    +(k:3) (+(j:3) A[k][j] * x[j]) * x[k]\n",
      "\n",
      "Function(x:[3]R, a:[3]R) : R\n",
      "    +(j:3) +(i:3) a[j] * (Gen(i:3) Gen(j:3) [i=j]*x[i])[j][i] * a[i]\n",
      "Function(x:[3]R, a:[3]R) : R\n",
      "    +(j:3) a[j] * x[j] * a[j]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Fqprod  = TypedFunc([('A',Rnn),('x',Rn)],qprod)\n",
    "print(Fqprod)\n",
    "Fqprod.gen_normalize()\n",
    "print(Fqprod)\n",
    "print()\n",
    "\n",
    "Fdprod  = TypedFunc([('x',Rn),('a',Rn)],dprod)\n",
    "print(Fdprod)\n",
    "Fdprod.gen_normalize()\n",
    "print(Fdprod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Implied Normal Form\n",
    "\n",
    "At this point, all of our valid programs (excepting those with pair-typed inputs and outputs) have been aggressively normalized.  However, it may seem hard to keep track of exactly what that normal form is.  Let's try to provide a loose BNF we can refer to here.\n",
    "\n",
    "$$\\begin{array}{rcl}\n",
    "  a &=&    a[i]\n",
    "    \\ |\\   x \\\\\n",
    "  e &=&    a\n",
    "    \\ |\\   c\n",
    "    \\ |\\   e_0 + e_1\n",
    "    \\ |\\   e_0 \\cdot e_1\n",
    "    \\ |\\   \\sum_i e\n",
    "    \\ |\\   [i=j] \\cdot e \\\\\n",
    "  g &=&    \\boxplus_i g\n",
    "  \\ \\ |\\ \\ e \\\\\n",
    "  s &=&    \\textrm{let } x = g \\textrm{ in } s\n",
    "  \\ \\ |\\ \\ g \\\\\n",
    "\\end{array}$$\n",
    "\n",
    "Observe how successive layers of forms have been peeled back into a standard nesting.  We have a sequence of statements, whose expressions begin with all the generators, followed by an expression totally free of `Let` and `Gen`.  This can now be translated to Halide, because each such line is a pure-definition of a Func. with the final expression being the output func.\n",
    "\n",
    "This normal form can be extracted after all the preceding transformations by using the following function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_block_norm(e):\n",
    "    stmts   = []\n",
    "    expr    = e\n",
    "    while type(expr) is IR.Let:\n",
    "        nm      = expr.name\n",
    "        e       = expr.rhs\n",
    "        gens    = []\n",
    "        while type(e) is IR.Gen:\n",
    "            i   = e.idxname\n",
    "            r   = e.range\n",
    "            gens.append((i,r))\n",
    "            e   = e.body\n",
    "        stmts.append((nm,gens,e))\n",
    "        expr    = expr.body\n",
    "    body_gens   = []\n",
    "    while type(expr) is IR.Gen:\n",
    "        i       = expr.idxname\n",
    "        r       = expr.range\n",
    "        body_gens.append((i,r))\n",
    "        expr    = expr.body\n",
    "        \n",
    "        \n",
    "    # stmts has form [( var_name, [( i_name, range )], (body_gens, body_expr) )]\n",
    "    return stmts, (body_gens,expr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Generation\n",
    "\n",
    "In order to generate code, we need to manage a context of name bindings, as well as inputs and outputs finally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Halide_CodeGen:\n",
    "    def __init__(self,expr,arg_symtyps,rettyp):        \n",
    "        # break out into a list of bindings and return expr\n",
    "        stmts, ret  = _get_block_norm(expr)\n",
    "        self._orig_stmts = stmts\n",
    "        self._orig_ret  = ret\n",
    "        \n",
    "        self._ctxt      = _Context()\n",
    "        self._first_run = True\n",
    "        \n",
    "        # helper function to process tensor types\n",
    "        def shape_dim(T):\n",
    "            if not type(T) is IR.TTensor: return []\n",
    "            else: return [T.range] + shape_dim(T.typ)\n",
    "        \n",
    "        # create Halide inputs for each argument\n",
    "        # inputs may be 'param's (scalars) or\n",
    "        #               'img_param's (tensors)\n",
    "        Hf64        = halide_type_t(C.type_float,64,1)\n",
    "        arg_params  = {}\n",
    "        for nm,typ in arg_symtyps.values():\n",
    "            nm_bytes    = repr(nm).encode('utf-8')\n",
    "            shape       = shape_dim(typ)\n",
    "            if len(shape) == 0: # scalar case\n",
    "                P = C.hwrap_new_param(nm_bytes,Hf64)\n",
    "                arg_params[nm.name()] = P\n",
    "                # also bind the arg symbol to an Expr\n",
    "                E = C.hwrap_param_to_expr(P)\n",
    "                self._ctxt.set( nm, E )\n",
    "            else: # tensor case\n",
    "                Img = C.hwrap_new_img(nm_bytes,len(shape),Hf64)\n",
    "                arg_params[nm.name()] = Img\n",
    "                # also bind the arg symbol to a Func\n",
    "                F   = C.hwrap_img_to_func(Img)\n",
    "                self._ctxt.set( nm, F )\n",
    "                # Halide auto-scheduling requires an estimate\n",
    "                # of tensor size, which we extract from the type\n",
    "                for i,r in enumerate(shape):\n",
    "                    C.hwrap_set_img_bound_estimate(Img,i,\n",
    "                        C.hwrap_i32_to_expr(0),C.hwrap_i32_to_expr(r))\n",
    "        self._arg_params    = arg_params\n",
    "        self._arg_typs      = { nm : symtyp[1]\n",
    "                                for nm,symtyp in arg_symtyps.items() }\n",
    "        \n",
    "        # compile each statement\n",
    "        for name,gens,body in stmts:\n",
    "            self._compile_stmt(name,gens,body)\n",
    "        \n",
    "        # compile the return expression as a statement\n",
    "        self._ret_sym       = Sym('return')\n",
    "        self._ret_Func      = self._compile_stmt(self._ret_sym,\n",
    "                                                 ret[0], ret[1])\n",
    "        self._ret_typ       = rettyp\n",
    "        # also provide output estimates for auto-scheduling\n",
    "        if type(rettyp) is IR.TTensor:\n",
    "            for i,r in enumerate(shape_dim(rettyp)):\n",
    "                C.hwrap_set_func_bound_estimate(self._ret_Func,i,\n",
    "                    C.hwrap_i32_to_expr(0),C.hwrap_i32_to_expr(r))\n",
    "        else: # scalar temporaries encoded as length 1 arrays\n",
    "            C.hwrap_set_func_bound_estimate(self._ret_Func,0,\n",
    "                C.hwrap_i32_to_expr(0),C.hwrap_i32_to_expr(1))\n",
    "        \n",
    "    \n",
    "    def _compile_stmt(self, name, gens, expr):\n",
    "        name_bytes  = repr(name).encode('utf-8')\n",
    "        F           = C.hwrap_new_func(name_bytes)\n",
    "        \n",
    "        self._ctxt.push()\n",
    "        \n",
    "        # create index variables\n",
    "        n_dims      = len(gens)\n",
    "        i_var_arr   = None\n",
    "        handles     = [] # to prevent garbage collection\n",
    "        if n_dims == 0:\n",
    "            i       = Sym(name.name()+\"_0idx\")\n",
    "            i_bytes = repr(i).encode('utf-8')\n",
    "            V       = C.hwrap_new_var(i_bytes)\n",
    "            handles.append(V)\n",
    "            i_var_arr   = (hw_var_t * 1)(V)\n",
    "            n_dims      = 1\n",
    "        else:\n",
    "            i_var_arr   = (hw_var_t * n_dims)()\n",
    "            for k,ir in enumerate(gens):\n",
    "                i, r    = ir\n",
    "                i_bytes = repr(i).encode('utf-8')\n",
    "                V       = C.hwrap_new_var(i_bytes)\n",
    "                E       = C.hwrap_var_to_expr(V)\n",
    "                handles.append(V)\n",
    "                handles.append(E)\n",
    "                # pack var into lhs array\n",
    "                i_var_arr[k] = V\n",
    "                # store expr in context\n",
    "                self._ctxt.set(i,E)\n",
    "        \n",
    "        # compile rhs expr\n",
    "        rhs = self._compile_expr(expr)\n",
    "        self._ctxt.pop()\n",
    "        \n",
    "        # add the statement to the program\n",
    "        C.hwrap_pure_def(F,n_dims,i_var_arr,rhs)\n",
    "        \n",
    "        # add the function to the context\n",
    "        if len(gens) == 0:\n",
    "            zero    = C.hwrap_i32_to_expr(0)\n",
    "            z_arr   = (hw_expr_t * 1)(zero)\n",
    "            E       = C.hwrap_access_func(F,1,z_arr)\n",
    "            self._ctxt.set(name,E)\n",
    "        else:\n",
    "            self._ctxt.set(name,F)\n",
    "        return F\n",
    "    \n",
    "    def _compile_expr(self,e):\n",
    "        eclass = type(e)\n",
    "        assert not eclass is IR.Pair, \"pairs should be eliminated\"\n",
    "        assert not eclass is IR.Proj, \"pairs should be eliminated\"\n",
    "        assert not eclass is IR.Let\n",
    "        assert not eclass is IR.Gen\n",
    "        if   eclass is IR.Var:\n",
    "            expr = self._ctxt.get(e.name)\n",
    "            assert expr != None\n",
    "            return expr\n",
    "        \n",
    "        elif eclass is IR.Const:\n",
    "            expr = C.hwrap_f64_to_expr(e.val)\n",
    "            return expr\n",
    "        \n",
    "        elif eclass is IR.Add or eclass is IR.Mul:\n",
    "            lhs  = self._compile_expr(e.lhs)\n",
    "            rhs  = self._compile_expr(e.rhs)\n",
    "            C_op = C.hwrap_add if eclass is IR.Add else C.hwrap_mul\n",
    "            res  = C_op(lhs,rhs)\n",
    "            return res\n",
    "        \n",
    "        elif eclass is IR.Sum:\n",
    "            self._ctxt.push()\n",
    "            # create rdom\n",
    "            rb   = repr(e.idxname).encode('utf-8')\n",
    "            lo   = C.hwrap_i32_to_expr(0)\n",
    "            hi   = C.hwrap_i32_to_expr(e.range)\n",
    "            rng  = (hw_expr_t * 2)(lo,hi)\n",
    "            rdom = C.hwrap_new_rdom(rb,1,rng)\n",
    "            # bind rdom in context as expr\n",
    "            rexp = C.hwrap_rdom_to_expr(rdom)\n",
    "            self._ctxt.set(e.idxname,rexp)\n",
    "            # finally compile body...\n",
    "            body = self._compile_expr(e.body)\n",
    "            self._ctxt.pop()\n",
    "            \n",
    "            res  = C.hwrap_big_sum(rdom,body)\n",
    "            return res\n",
    "        \n",
    "        elif eclass is IR.Access:\n",
    "            return self._compile_access(e)\n",
    "        \n",
    "        elif eclass is IR.Indicate:\n",
    "            li      = self._ctxt.get(e.arg.lhs)\n",
    "            ri      = self._ctxt.get(e.arg.rhs)\n",
    "            assert type(li) == hw_expr_t\n",
    "            assert type(ri) == hw_expr_t\n",
    "            \n",
    "            eq      = C.hwrap_eq(li,ri)\n",
    "            body    = self._compile_expr(e.body)\n",
    "            zero    = C.hwrap_f64_to_expr(0.0)\n",
    "            res     = C.hwrap_select(eq, body, zero)\n",
    "            return res\n",
    "            \n",
    "        else: assert False, \"unrecognized IR case\"\n",
    "    \n",
    "    def _compile_access(self,e):\n",
    "        idxs    = []\n",
    "        while type(e) is IR.Access:\n",
    "            # note that we pull off accesses right-to-left\n",
    "            idxs.insert(0,e.idx)\n",
    "            e = e.base\n",
    "        assert type(e) is IR.Var\n",
    "        F       = self._compile_expr(e)\n",
    "        assert type(F) is hw_func_t\n",
    "        \n",
    "        # lookup index expressions, and create access\n",
    "        n_idx   = len(idxs)\n",
    "        exprs   = [ self._ctxt.get(i)\n",
    "                    for i in idxs ]\n",
    "        idx_arr = (hw_expr_t * n_idx)(*exprs)\n",
    "        a   = C.hwrap_access_func(F,n_idx,idx_arr)\n",
    "        return a\n",
    "        \n",
    "    def run(self,inputs,outputs):\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so this defines a Halide pipeline.  We still need a way to run it.\n",
    "\n",
    "## Handling Parameters\n",
    "\n",
    "Recall that we defined `ndarray_to_halide_buf(ndarray)` as a function to help convert from NumPy to Halide data descriptors.  Now, we need a few more details to help out.\n",
    "\n",
    "* We need a way to handle scalar inputs and outputs.\n",
    "* We need a way to type-check inputs and outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _type_value_match(typ,val):\n",
    "    if type(typ) is IR.Pair:\n",
    "        raise TypeError(\"Pairs unsupported\")\n",
    "    elif type(typ) is IR.TTensor:\n",
    "        # unroll tensor\n",
    "        shape = []\n",
    "        while type(typ) is IR.TTensor:\n",
    "            shape.append(typ.range)\n",
    "            typ = typ.typ\n",
    "        if type(typ) is IR.Pair:\n",
    "            raise TypeError(\"Pairs unsupported\")\n",
    "        assert typ is IR.tnum\n",
    "        \n",
    "        if type(val) != np.ndarray:\n",
    "            raise TypeError(\"Expected 'numpy.ndarray' type value\")\n",
    "        # check shape\n",
    "        if len(shape) != len(val.shape):\n",
    "            raise TypeError(f\"Expected {len(shape)} dims, but got \"\n",
    "                            f\"an ndarray with {len(val.shape)}\")\n",
    "        for i,d in enumerate(shape):\n",
    "            if d != val.shape[i]:\n",
    "                raise TypeError(f\"expected dimension {i} of tensor shape \"\n",
    "                                f\"to be {d}, but it was {val.shape[i]}\")\n",
    "        \n",
    "    elif typ is IR.tnum:\n",
    "        if type(val) != float and type(val) != int:\n",
    "            raise TypeError(\"Expected 'float' or 'int' type value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[5. , 2. , 0. ],\n",
      "       [2.2, 0. , 4.5],\n",
      "       [0. , 6.1, 3.3]])\n",
      "Expected 1 dims, but got an ndarray with 2\n",
      "expected dimension 0 of tensor shape to be 4, but it was 3\n",
      "Expected 'numpy.ndarray' type value\n"
     ]
    }
   ],
   "source": [
    "print(repr(Av))\n",
    "_type_value_match(Rnn,Av)\n",
    "_type_value_match(Rn,cv)\n",
    "_type_value_match(R,3)\n",
    "try: _type_value_match(Rn,Av)\n",
    "except TypeError as e: print(e)\n",
    "try: _type_value_match(IR.TTensor(4,Rn),Av)\n",
    "except TypeError as e: print(e)\n",
    "try: _type_value_match(Rn,3.4)\n",
    "except TypeError as e: print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preceding gives us a simple way to type-check.  In order to bind scalar inputs, we simply need to decide which case we're in (scalar or tensor) and bind to a param or image-param appropriately.  The output may be a bit trickier because we need to bind an otherwise spurious 1-entry tensor to handle scalar output.  This also raises the question of how output allocations should be handled.  It seems a given that the input should be allocated by the caller.  However, the callee often allocates the output.\n",
    "\n",
    "In order to prevent possibly unwanted allocations, we'll just accept a \"pre-allocated\" output parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _Halide_CodeGen_run_pipeline(self,inputs,output=None):\n",
    "    # check and bind input arguments\n",
    "    hbufs = []\n",
    "    for nm in self._arg_params: # that all inputs are defined\n",
    "        if not nm in inputs:\n",
    "            raise TypeError(f\"expected input argument '{nm}'\")\n",
    "    for nm,val in inputs.items():\n",
    "        if not nm in self._arg_typs:\n",
    "            raise TypeError(f\"unexpected input, named '{nm}'\")\n",
    "        T = self._arg_typs[nm]\n",
    "        _type_value_match(T,val)\n",
    "        P = self._arg_params[nm]\n",
    "        if T is IR.tnum: # scalar\n",
    "            assert type(P) is hw_param_t\n",
    "            C.hwrap_set_param(P, ctypes.byref(ctypes.c_double(val)))\n",
    "        else:\n",
    "            assert type(P) is hw_img_t\n",
    "            hbuf = ndarray_to_halide_buf(val)\n",
    "            hbufs.append(hbuf) # prevent early de-allocation\n",
    "            C.hwrap_set_img(P, ctypes.byref(hbuf))\n",
    "    \n",
    "    # handle unsupplied output...\n",
    "    if output is None:\n",
    "        typ = self._ret_typ\n",
    "        if typ is IR.tnum: # scalar case\n",
    "            output = np.array([0.0])\n",
    "        else: # tensor case\n",
    "            shape = []\n",
    "            while type(typ) is IR.TTensor:\n",
    "                shape.append(typ.range)\n",
    "                typ = typ.typ\n",
    "            assert typ is IR.tnum\n",
    "            \n",
    "            output = np.ndarray(dtype='double', shape=shape, order='F')\n",
    "    # check output\n",
    "    if self._ret_typ is IR.tnum:\n",
    "        if (type(output) != np.ndarray or\n",
    "            len(output.shape) != 1 or\n",
    "            output.shape[0] != 1):\n",
    "                raise TypeError(\"Expected numpy.ndarray of shape [1]\")\n",
    "    else:\n",
    "        _type_value_match(self._ret_typ, output)\n",
    "    # bind output\n",
    "    outbuf  = ndarray_to_halide_buf(output)\n",
    "    hbufs.append(outbuf)\n",
    "    \n",
    "    # make sure the pipeline is auto-scheduled\n",
    "    if self._first_run:\n",
    "        self._first_run = False\n",
    "        #C.hwrap_autoschedule_func( self._ret_Func )\n",
    "        \n",
    "    # run the pipeline\n",
    "    C.hwrap_realize_func( self._ret_Func, outbuf )\n",
    "    \n",
    "    # potentially extract the output\n",
    "    return_val = output\n",
    "    if self._ret_typ is IR.tnum:\n",
    "        return_val = output[0]\n",
    "    return return_val\n",
    "\n",
    "Halide_CodeGen.run = _Halide_CodeGen_run_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it Together\n",
    "\n",
    "We've defined a compilation strategy that looks like the following for some Tensor-language expression `e` written in `IRv0` and signature `argtyps` with form `{ name : IRv0_type }`:\n",
    "\n",
    "```\n",
    "TF = TypedFunc(argtyps,e)\n",
    "# normalization passes\n",
    "TF.eliminate_pairs()\n",
    "TF.lift_lets()\n",
    "TF.gen_normalize()\n",
    "# compilation pass\n",
    "TF.compile()\n",
    "\n",
    "# only this need be invoked on each further execution\n",
    "TF.run(argvals)\n",
    "```\n",
    "\n",
    "What we need now is to create `compile()` and `run()` wrappers on the typed-func class.  We'll have compilation take care of all the normalization while we're at it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _TypedFunc_compile(self):\n",
    "    # protect against re-compilation\n",
    "    try:\n",
    "        getattr(self,'_compiled_obj')\n",
    "        return\n",
    "    except: pass\n",
    "    # run normalization\n",
    "    self.eliminate_pairs()\n",
    "    self.lift_lets()\n",
    "    self.gen_normalize()\n",
    "    # do the compilation via the CodeGen object\n",
    "    e       = self._expr\n",
    "    atyps   = self._symtyps\n",
    "    CG      = Halide_CodeGen(e,atyps,e.typ)\n",
    "    self._compiled_obj = CG\n",
    "\n",
    "def _TypedFunc_run(self,inputs,output=None):\n",
    "    self.compile()\n",
    "    # actual execution\n",
    "    return self._compiled_obj.run(inputs,output)\n",
    "\n",
    "TypedFunc.compile   = _TypedFunc_compile\n",
    "TypedFunc.run       = _TypedFunc_run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can pack this into the original Func, neatly hiding everything behind that interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _Func_jit_compile(self):\n",
    "    try: getattr(self,'_typed_func'); return\n",
    "    except: pass\n",
    "    \n",
    "    self._typed_func = TypedFunc(self._arglist,self._expr)\n",
    "    self._typed_func.compile()\n",
    "\n",
    "def Func_jit_exec(self, *args, **kwargs):\n",
    "    self._jit_compile()\n",
    "    call_args   = {}\n",
    "\n",
    "    # check that the right number of arguments were used\n",
    "    n_call      = len(args) + len(kwargs)\n",
    "    n_args      = len(self._arglist)\n",
    "    if n_call != n_args:\n",
    "        raise TypeError(f\"expected {n_args} arguments, \"\n",
    "                        f\"but was called with {n_call}\")\n",
    "\n",
    "    # fill out call_args with supplied named arguments\n",
    "    for nm in kwargs:\n",
    "        typ     = self._argdict.get(nm)\n",
    "        if typ is None:\n",
    "            raise TypeError(f\"argument '{nm}' is not an argument of \"\n",
    "                            f\"this tensor function\")\n",
    "        else:\n",
    "            call_args[nm] = kwargs[nm]\n",
    "\n",
    "    # then fill in the remainder with the unnamed arguments\n",
    "    arg_i   = 0\n",
    "    for nm,typ in self._arglist:\n",
    "        if not nm in call_args:\n",
    "            assert(arg_i < len(args))\n",
    "            val     = args[arg_i]\n",
    "            arg_i   = arg_i + 1\n",
    "            call_args[nm] = val\n",
    "\n",
    "    # finally, execute\n",
    "    return self._typed_func.run(call_args)\n",
    "\n",
    "Func._jit_compile = _Func_jit_compile\n",
    "Func.jit_exec = Func_jit_exec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to test what we've got here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<atlv0.Func object at 0x10e5e4208>\n",
      "<atlv0.Func object at 0x10e5e43c8>\n",
      "<atlv0.Func object at 0x10e5e4438>\n",
      "<atlv0.Func object at 0x10e5e44a8>\n",
      "<atlv0.Func object at 0x10e5193c8>\n",
      "<atlv0.Func object at 0x10e519400>\n",
      "<atlv0.Func object at 0x10e5a1198>\n"
     ]
    }
   ],
   "source": [
    "n       = 3\n",
    "R       = IR.tnum\n",
    "Rn      = IR.TTensor(n,R)\n",
    "Rnn     = IR.TTensor(n,Rn)\n",
    "Rnnn    = IR.TTensor(n,Rnn)\n",
    "x       = IRv0.Var('x')\n",
    "A, D    = IRv0.Var('A'), IRv0.Var('D')\n",
    "a, b, c = IRv0.Var('a'), IRv0.Var('b'), IRv0.Var('c')\n",
    "i, j, k = 'i', 'j', 'k'\n",
    "\n",
    "store_order = 'F'\n",
    "xv = np.array([4.,7.,1.], order=store_order)\n",
    "Av = np.array([[5.,2.,0.],[2.2,0.,4.5],[0.,6.1,3.3]], order=store_order)\n",
    "av = np.array([9.2,5.4,7.1], order=store_order)\n",
    "bv = np.array([0.3,2.1,1.6], order=store_order)\n",
    "cv = np.array([0.,0.,1.], order=store_order)\n",
    "Dv = np.array([[[ 1., 2., 3.],[ 4., 5., 6.],[ 7., 8., 9.]],\n",
    "               [[10.,11.,12.],[13.,14.,15.],[16.,17.,18.]],\n",
    "               [[19.,20.,21.],[22.,23.,24.],[25.,26.,27.]]], order=store_order)\n",
    "\n",
    "pp2     = IRv0.Pair\n",
    "p0      = lambda x: IRv0.Proj(0, x)\n",
    "p1      = lambda x: IRv0.Proj(1, x)\n",
    "let     = lambda x,r,b: IRv0.Let(x,r,b)\n",
    "Gen     = lambda i,r,e: IRv0.Gen(i,r,e)\n",
    "Sum     = lambda i,r,e: IRv0.Sum(i,r,e)\n",
    "\n",
    "\n",
    "Axc     = Gen(i,n, c[i] + Sum(j,n, A[i,j] * x[j] ))\n",
    "tr      = Sum(i,n, A[i,i])\n",
    "diag    = Gen(i,n, Gen(j,n, IRv0.Eq(i,j) * x[i] ))\n",
    "ab3     = let('x', Gen(j,n, pp2( pp2(a[j], b[j]), a[j]*b[j] )),\n",
    "              Sum(j,n, p0(p0(x[j])) + p1(p0(x[j])) + p1(x[j]) ))\n",
    "ctrct   = Gen(i,n, Sum(j,n, let('x', Sum(k,n, D[i,j,k] * a[k]),\n",
    "                                 x * b[j] )))\n",
    "prod    = Gen(i,n, Sum(j,n, A[i,j] * x[j] ))\n",
    "qprod   = Sum(k,n, prod[k] * x[k])\n",
    "dprod   = Sum(j,n, Sum(i,n, a[j] * diag[j,i] * a[i] ))\n",
    "\n",
    "FAxc    = Func([('A',Rnn),('x',Rn),('c',Rn)], Axc)\n",
    "Ftr     = Func([('A',Rnn)], tr)\n",
    "Fdiag   = Func([('x',Rn)], diag)\n",
    "Fab3    = Func([('a',Rn),('b',Rn)], ab3)\n",
    "Fctrct  = Func([('D',Rnnn),('a',Rn),('b',Rn)], ctrct)\n",
    "Fqprod  = Func([('A',Rnn),('x',Rn)], qprod)\n",
    "Fdprod  = Func([('x',Rn),('a',Rn)] ,dprod)\n",
    "\n",
    "print(FAxc)\n",
    "print(Ftr)\n",
    "print(Fdiag)\n",
    "print(Fab3)\n",
    "print(Fctrct)\n",
    "print(Fqprod)\n",
    "print(Fdprod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "FAxc._jit_compile()\n",
    "Ftr._jit_compile()\n",
    "Fdiag._jit_compile()\n",
    "Fab3._jit_compile()\n",
    "Fctrct._jit_compile()\n",
    "Fqprod._jit_compile()\n",
    "Fdprod._jit_compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run Test:  Axc\n",
      "[[5.  2.  0. ]\n",
      " [2.2 0.  4.5]\n",
      " [0.  6.1 3.3]] [4. 7. 1.] [0. 0. 1.]\n",
      "compiled:     [34.  13.3 47. ]\n",
      "interpreted:  [34.0, 13.3, 46.99999999999999]\n",
      "Run Test:  tr\n",
      "[[5.  2.  0. ]\n",
      " [2.2 0.  4.5]\n",
      " [0.  6.1 3.3]]\n",
      "compiled:     8.3\n",
      "interpreted:  8.3\n",
      "Run Test:  diag\n",
      "[4. 7. 1.]\n",
      "compiled:     [[4. 0. 0.]\n",
      " [0. 7. 0.]\n",
      " [0. 0. 1.]]\n",
      "interpreted:  [[4.0, 0.0, 0.0], [0.0, 7.0, 0.0], [0.0, 0.0, 1.0]]\n",
      "Run Test:  ab3\n",
      "[9.2 5.4 7.1] [0.3 2.1 1.6]\n",
      "compiled:     51.16\n",
      "interpreted:  51.16\n",
      "Run Test:  ctrct\n",
      "[[[ 1.  2.  3.]\n",
      "  [ 4.  5.  6.]\n",
      "  [ 7.  8.  9.]]\n",
      "\n",
      " [[10. 11. 12.]\n",
      "  [13. 14. 15.]\n",
      "  [16. 17. 18.]]\n",
      "\n",
      " [[19. 20. 21.]\n",
      "  [22. 23. 24.]\n",
      "  [25. 26. 27.]]] [9.2 5.4 7.1] [0.3 2.1 1.6]\n",
      "compiled:     [ 510.23 1291.43 2072.63]\n",
      "interpreted:  [510.23, 1291.43, 2072.6299999999997]\n",
      "Run Test:  qprod\n",
      "[[5.  2.  0. ]\n",
      " [2.2 0.  4.5]\n",
      " [0.  6.1 3.3]] [4. 7. 1.]\n",
      "compiled:     275.1\n",
      "interpreted:  275.1\n",
      "Run Test:  dprod\n",
      "[4. 7. 1.] [9.2 5.4 7.1]\n",
      "compiled:     593.0899999999999\n",
      "interpreted:  593.0899999999999\n"
     ]
    }
   ],
   "source": [
    "def test(name,F,*args):\n",
    "    print('Run Test: ',name)\n",
    "    print(*args)\n",
    "    l_args = [ a.tolist() for a in args ]\n",
    "    print('compiled:    ', F.jit_exec(*args))\n",
    "    print('interpreted: ', F.interpret(*l_args))\n",
    "\n",
    "test(\"Axc\",FAxc,Av,xv,cv)\n",
    "test(\"tr\",Ftr,Av)\n",
    "test(\"diag\",Fdiag,xv)\n",
    "test(\"ab3\",Fab3,av,bv)\n",
    "test(\"ctrct\",Fctrct,Dv,av,bv)\n",
    "test(\"qprod\",Fqprod,Av,xv)\n",
    "test(\"dprod\",Fdprod,xv,av)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comments\n",
    "\n",
    "This was a long slog, but we got all the way to a compiled version of the tensor language.  We don't necessarily have a very good sense of performance, but that doesn't have to be an overriding concern right now.\n",
    "\n",
    "Rather, the big limitation of this experiment was the complexity overload of all the unanticipated hoop-jumping.  To get this to be cleaner, we need to start thinking about how to break apart our previously compact compiler into multiple, distinct IRsâ€”each of which has a particular role to play.\n",
    "\n",
    "What might this look like?\n",
    "\n",
    "1. We ought to clean-up the front-end IR a bit more.  We can now expect that type-checking will mark a boundary from this front-end to the back-end.  We ought to be able to reverse this mapping for at least the benefit of serializing functions.\n",
    "2. We ought to treat the internal IR in as normalized a form as possible.  Is there some way to avoid so many different passes to transform it down?\n",
    "3. We might want to create an explicit Halide IR to simplify the code-generation.\n",
    "\n",
    "However, the _type system_ is shared in common amongst different IRs.  This suggests we need to factor out the type-system.\n",
    "\n",
    "In addition to separating out these IRs, we also ought to have more robust testing.  Certainly we forgot something in our haste (e.g. literal-int indices in accesses).  Testing infrastructure might be able to help us out tremendously and efficiently.\n",
    "\n",
    "Lastly, we ought to clean up the way compiler passes get written.  We seemed to settle on a \"pass-as-class\" style.  However, certain objects such as `_Context` tended to be very important.  Is there any way we can standardize our pass-writing further?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extensions\n",
    "\n",
    "In addition to re-factoring, we need to fundamentally extend the basic IR.  Recall its definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "module IR_v0 {\n",
      "    expr = Var      ( string name )\n",
      "         | Const    ( float  val  )\n",
      "         | Add      ( expr lhs, expr rhs )\n",
      "         | Mul      ( expr lhs, expr rhs )\n",
      "         | Pair     ( expr lhs, expr rhs )\n",
      "         | Proj     ( int01 idx, expr arg )\n",
      "         | Gen      ( string idxname, int range, expr body )\n",
      "         | Sum      ( string idxname, int range, expr body )\n",
      "         | Access   ( expr  base, index idx )\n",
      "         -- implied multiplication of the bracket with body\n",
      "         | Indicate ( pred  arg, expr body )\n",
      "         -- important to express sharing of computation results\n",
      "         | Let      ( string name, expr rhs, expr body )\n",
      "    \n",
      "    -- indices are drawn from a range s.t.\n",
      "    -- 0 <= i < range\n",
      "    \n",
      "    pred    = Eq( index lhs, index rhs )\n",
      "    \n",
      "    type    = TNum    ()\n",
      "            | TError  ()\n",
      "            | TPair   (  type lhs, type rhs )\n",
      "            | TTensor ( int range, type typ )\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(IRv0._defstr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need to expand the `pred` class with other concepts in order to capture tensor sparsity patterns.\n",
    "\n",
    "```\n",
    "    pred    = Peq     ( iexp lhs, iexp rhs )\n",
    "            | Pneq    ( iexp lhs, iexp rhs )\n",
    "            | Plt     ( iexp lhs, iexp rhs )\n",
    "            | Pleq    ( iexp lhs, iexp rhs )\n",
    "            | Prel    ( relation r, iexp* args )\n",
    "            | Pand    ( pred lhs, pred rhs )\n",
    "            | Por     ( pred lhs, pred rhs )\n",
    "            | Pnot    ( pred arg )\n",
    "            \n",
    "    iexp    = Ivar    ( symbol name )\n",
    "            | Imul    ( int    c, iexp arg )\n",
    "            | Iadd    ( iexp lhs, iexp rhs )\n",
    "            | Iconst  ( int val )\n",
    "```\n",
    "\n",
    "This set of concepts contains affine-indexing expressions via `Imul` and `Iadd`, plus the comparison predicates.  Additionally, there are Boolean connectives, and `Prel`, which allows for data-defined predicatesâ€”which are relations in the database sense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider as a suggestive example, matrix-matrix multiplication with sparse matrices whose sparsity patterns are governed by relations.\n",
    "\n",
    "$$\\begin{array}{rcl}\n",
    "S &:& [n,m]\\mathbb{2} \\\\\n",
    "T &:& [m,p]\\mathbb{2} \\\\\n",
    "A &:& [n,m]\\mathbb{R} <: S \\\\\n",
    "B &:& [m,p]\\mathbb{R} <: T \\\\\n",
    "M &=& \\boxplus_{i,k} \\sum_{j} A[i,j] \\cdot B[j,k] \\\\\n",
    "\\end{array}$$\n",
    "\n",
    "We can propagate the sparsity constraints using the Iverson-bracket indicator function:\n",
    "\n",
    "$$\\begin{array}{rcl}\n",
    "M &=& \\boxplus_{i,k} \\sum_{j} A[i,j] \\cdot B[j,k] \\\\\n",
    "  &=& \\boxplus_{i,k} \\sum_{j} [S(i,j)] \\cdot A[i,j] \\cdot [T(j,k)] \\cdot B[j,k] \\\\\n",
    "  &=& \\boxplus_{i,k} \\sum_{j} [S(i,j)] \\cdot A[i,j] \\cdot [T(j,k)] \\cdot B[j,k] \\\\\n",
    "  &=& \\boxplus_{i,k} [\\exists_j S(i,j)\\wedge T(j,k)]\\sum_{j} \\cdot A[i,j] \\cdot B[j,k] \\\\\n",
    "\\end{array}$$\n",
    "\n",
    "This final structure predicate $\\exists_j S(i,j)\\wedge T(j,k)$, is a join on $j : m$ between $S$ and $T$ followed by a projection onto $i,k$, dropping $j$.  This new structure relation can be pre-computed separately from $M$ or computed at the same time as $M$.  However, we mostly lack the requisite subtlety in our language IR to capture these distinctions.\n",
    "\n",
    "For instance, suppose we simply want to restrict the looping using the sparsity structure.  We need a way to de-couple the loop index ordering from the summation-reduction behavior, and also figure in the join-behavior of the relations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
