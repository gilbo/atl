{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asdl\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from src.adt import ADT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frequently when working with intermediate representations in a compiler, we want to ensure a unique identity of nodes.  We can do this very neatly using memoization.  Therefore, it's worth the trouble to see if we can incorporate memoization directly into the constructors from the ASDL module.\n",
    "\n",
    "One complication we will run into is that a memoization `dict` will by default ensure that every constructed object cannot be garbage collected.  This seems, and is essentially bad behavior.  It can be avoided by treating all references from the memoization `dict` as weak, so that they are not—in and of themselves—sufficient to keep the object alive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from weakref import WeakValueDictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us start with an example IR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = ADT(\"\"\"\n",
    "module P\n",
    "{\n",
    "  expr = Var(string name)\n",
    "       | Const(float val)\n",
    "       | Add(expr lhs, expr rhs)\n",
    "       | Mul(expr lhs, expr rhs)\n",
    "}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now consider the expression `(x*x)*(x*x)`.  If properly memoized, there should be exactly 3 nodes: `x`, `x*x` and the final product.  First, let's consider memoizing `Var`.  We will try a wrapper function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_v0_cache = WeakValueDictionary({})\n",
    "def memo_var_v0(name):\n",
    "    v = var_v0_cache.get(name)\n",
    "    if v == None:\n",
    "        v = P.Var(name)\n",
    "        var_v0_cache[name] = v\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x  = memo_var_v0('x')\n",
    "x0 = memo_var_v0('x')\n",
    "x == x0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could even hide the fact that we've done this manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Var = memo_var_v0\n",
    "type(x) is Var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmmm, except that causes another problem.  Does this mean that we will have to use special constructor functions whenever we want to memoize IR objects?  Possibly not.  To avoid that, we need a way to hijack the object creation process and (when a cache lookup succeeds) return a different object than the one that would normally be created.\n",
    "\n",
    "Python gives us a way to do this via the `__new__` function on classes.  We could directly muck with `Var.__new__`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "P.Var._memo_cache = WeakValueDictionary({})\n",
    "def _Var_new_memo(cls, name):\n",
    "    v = P.Var._memo_cache.get(name)\n",
    "    if v == None:\n",
    "        v = super(P.Var,cls).__new__(cls)\n",
    "        P.Var._memo_cache[name] = v\n",
    "    return v\n",
    "P.Var.__new__ = _Var_new_memo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x  = P.Var('x')\n",
    "x0 = P.Var('x')\n",
    "print(type(x) is P.Var, type(x0) is P.Var)\n",
    "x == x0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, one question is whether we waste the time re-initializing the object and what that does.  Let's create our own little test object to see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init with name: x\n",
      "init with name: x\n",
      "{'name': 'x', 'foo': 3}\n",
      "init with name: x\n",
      "{'name': 'x', 'foo': 3}\n"
     ]
    }
   ],
   "source": [
    "class MyVar:\n",
    "    _memo_cache = WeakValueDictionary({})\n",
    "    def __new__(cls,name):\n",
    "        v = MyVar._memo_cache.get(name)\n",
    "        if v == None:\n",
    "            v = super(MyVar,cls).__new__(cls)\n",
    "            MyVar._memo_cache[name] = v\n",
    "        return v\n",
    "    \n",
    "    def __init__(self,name):\n",
    "        print('init with name: '+name)\n",
    "        self.name = name\n",
    "\n",
    "x = MyVar('x')\n",
    "x = MyVar('x')\n",
    "x.foo = 3\n",
    "print(x.__dict__)\n",
    "y = MyVar('x')\n",
    "print(y.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we are definitely \"wasting\" time doing re-initialization.  However, we're also not disrupting anything else about the object.  So maybe that's ok for a first pass at this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a strategy for how to sneak the memoization into the constructor classes pretty transparently.  However, we need a way to code-generate the appropriate memoization for the potentially multi-argument constructors.  This also means we need a multi-key (and different kinds of value-supporting) approach to the memoization dictionary.  Let's investigate how that might work out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4438257096\n",
      "4438253896\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "dd = {}\n",
    "print(id( (2,5) ))\n",
    "print(id( (2,5) ))\n",
    "dd[(2,5)] = 24\n",
    "print(dd.get( (2,5) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tuples don't have stable `id`s, but they do behave well as keys.  Objects do not work as keys and need their `id` taken.  It's a bit confusing.  But some searching around reveals that the following types should work fine as dictionary keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True, True, True, True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "( type(3) is int,\n",
    "  type(5.4) is float,\n",
    " type(\"ibasdf\") is str,\n",
    " type(True) is bool,\n",
    " type((1,2)) is tuple )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, let's build a `_to_key` helper function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _to_key(v):\n",
    "    tv = type(v)\n",
    "    if ( tv is int or tv is float or\n",
    "         tv is str or tv is bool or\n",
    "         tv is tuple ):\n",
    "        return v\n",
    "    else:\n",
    "        return id(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to deal with optional values as well.  What happens if we try to memoize on `None`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "dd = {}\n",
    "dd[None] = 3\n",
    "print(dd[None])\n",
    "dd[(None,None)] = 4\n",
    "print(dd[(None,None)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And what about sequences (i.e. lists)?  Those do not work as keys.  Therefore, we need a special function to help memoize lists.  It turns out that we can just convert them to tuples (woah!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "xs = [1,2,3]\n",
    "ys = [1,2,3]\n",
    "dd = {}\n",
    "dd[tuple(xs)] = 5\n",
    "print(dd.get(tuple(xs)))\n",
    "print(dd.get(tuple(ys)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're set to create a proper, robust IR memoization support."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "_builtin_keymap = {\n",
    "    'string'  : lambda x: x,\n",
    "    'int'     : lambda x: x,\n",
    "    'object'  : id,\n",
    "    'float'   : lambda x: x,\n",
    "    'bool'    : lambda x: x,\n",
    "}\n",
    "\n",
    "def _add_memoization(mod,whitelist,ext_key):\n",
    "    asdl_mod = mod._ast\n",
    "    \n",
    "    keymap = _builtin_keymap.copy()\n",
    "    for nm,fn in ext_key.items():\n",
    "        keymap[nm] = fn\n",
    "    for nm in asdl_mod.types:\n",
    "        keymap[nm] = id\n",
    "    \n",
    "    def create_listkey(f):\n",
    "        i = 'i' if f.name != i else 'ii'\n",
    "        return (f\"tuple([ K['{f.type}']({i}) \"\n",
    "                f\"for {i} in {f.name} ]),\")\n",
    "    def create_optkey(f):\n",
    "        return (f\"None if {f.name} == None else \"\n",
    "                f\"K['{f.type}']({f.name}),\")\n",
    "    \n",
    "    def create_newfn(name, fields):\n",
    "        if not name in whitelist: return\n",
    "        T       = getattr(mod,name)\n",
    "        \n",
    "        argstr  = ', '.join([ f.name for f in fields ])\n",
    "        keystr  = '('+(''.join([\n",
    "            create_listkey(f) if f.seq else\n",
    "            create_optkey(f)  if f.opt else\n",
    "            f\"K['{f.type}']({f.name}),\"\n",
    "            for f in fields\n",
    "        ]))+')'\n",
    "        \n",
    "        exec_out = { 'T': T, 'K': keymap }\n",
    "        exec_str = (f\"def {name}_new(cls,{argstr}):\\n\"\n",
    "                    f\"    key = {keystr}\\n\"\n",
    "                    f\"    val = T._memo_cache.get(key)\\n\"\n",
    "                    f\"    if val == None:\\n\"\n",
    "                    f\"        val = super(T,cls).__new__(cls)\\n\"\n",
    "                    f\"        T._memo_cache[key] = val\\n\"\n",
    "                    f\"    return val\")\n",
    "        # un-comment this line to see what's\n",
    "        # really going on\n",
    "        print(exec_str)\n",
    "        exec(exec_str, exec_out)\n",
    "        \n",
    "        T._memo_cache = WeakValueDictionary({})\n",
    "        T.__new__     = exec_out[name + '_new']\n",
    "        \n",
    "    def expand_sum(typ_name,t):\n",
    "        T          = getattr(mod,typ_name)\n",
    "        afields    = t.attributes\n",
    "        for c in t.types:\n",
    "            create_newfn(c.name, c.fields + afields)\n",
    "    \n",
    "    for nm,t in asdl_mod.types.items():\n",
    "        if isinstance(t,asdl.Product):\n",
    "            create_newfn(nm,t.fields)\n",
    "        elif isinstance(t,asdl.Sum):\n",
    "            expand_sum(nm,t)\n",
    "        else: assert false, \"unexpected kind of asdl type\"\n",
    "\n",
    "def memo(mod, whitelist, ext_key={}):\n",
    "    _add_memoization(mod,whitelist,ext_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def Var_new(cls,name):\n",
      "    key = (K['string'](name),)\n",
      "    val = T._memo_cache.get(key)\n",
      "    if val == None:\n",
      "        val = super(T,cls).__new__(cls)\n",
      "        T._memo_cache[key] = val\n",
      "    return val\n",
      "def Const_new(cls,val):\n",
      "    key = (K['float'](val),)\n",
      "    val = T._memo_cache.get(key)\n",
      "    if val == None:\n",
      "        val = super(T,cls).__new__(cls)\n",
      "        T._memo_cache[key] = val\n",
      "    return val\n",
      "def Add_new(cls,lhs, rhs):\n",
      "    key = (K['expr'](lhs),K['expr'](rhs),)\n",
      "    val = T._memo_cache.get(key)\n",
      "    if val == None:\n",
      "        val = super(T,cls).__new__(cls)\n",
      "        T._memo_cache[key] = val\n",
      "    return val\n",
      "def Mul_new(cls,lhs, rhs):\n",
      "    key = (K['expr'](lhs),K['expr'](rhs),)\n",
      "    val = T._memo_cache.get(key)\n",
      "    if val == None:\n",
      "        val = super(T,cls).__new__(cls)\n",
      "        T._memo_cache[key] = val\n",
      "    return val\n",
      "4444128872\n",
      "4443989720 4443989720\n",
      "4444131168 4444131168 4444131168 4444131168\n"
     ]
    }
   ],
   "source": [
    "memo(P,['Var','Const','Add','Mul'])\n",
    "\n",
    "x = P.Var('x')\n",
    "xx = P.Mul(x,x)\n",
    "xxxx = P.Mul(xx,xx)\n",
    "print(id(xxxx))\n",
    "print(id(xxxx.lhs),id(xxxx.rhs))\n",
    "print(id(xxxx.lhs.lhs),id(xxxx.lhs.rhs),id(xxxx.rhs.lhs),id(xxxx.rhs.rhs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
